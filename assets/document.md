MySQL数据库：
1、索引：
(1)不用遍历，基本上直接定位数据，加快数据查询速度；但在插入和修改数据时，因为要对索引也进行更新，所以要花费较多额外时间，且索引会增加了数据库的存储空间；
(2)innoDB默认索引类型为B+树，非叶节点仅具有索引作用，叶子结点的指针指向的是被索引的完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。这种索引叫做“聚焦索引”且叶子节点之间形成链表，从而方便了叶子结点的遍历与范围查找；
①在InnoDB有一个特殊的功能叫做自适应哈希索引，当它发现某些索引值被使用的非常频繁时，它会在内存中基于B+树索引之上再创建一个hash索引，加快数据的查找速度。
②聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索（非聚焦索引）需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录；所以效率低一点；
(3)哈希虽然能够提供O（1）的单数据行性能，但是对于范围查询和排序却无法很好地支持，最终导致全表扫描；B树能够在非叶节点中存储数据，但是这也导致在查询连续数据时可能会带来更多的随机I/O，B+树的所有叶节点可以通过指针相互连接，能够减少顺序遍历时产生的额外随机I/O；
(4)聚簇索引&非聚簇索引：
①InnoDB的主键使用的都是聚簇索引，而MyASM无论是主键索引还是二级索引，使用的都是非聚簇索引。
②聚簇索引的查找记录要比非聚簇索引块，因为聚簇索引是将索引和整条记录存放在一起，找到索引就找到了记录，而非聚簇索引只存储索引字段和记录所在的位置，通过索引找到记录所在的位置，然后再根据记录所在位置去获取记录；
③一个数据表只能有一个聚簇索引，但可以有多个非聚簇索引；
(5)索引的最左前缀原则：在使用复合索引（在多个列上建立索引，在多条件查询时，效率较高）作为条件查询时，必须使用到该索引中的第一个字段作为条件才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致。
2、事务和隔离：
(1)事务是恢复和并发控制的基本单位，是指作为单个逻辑工作单元执行的一系列操作，要么完全地执行，要么完全地不执行；在关系型数据库中，一个事务可以是一条SQL语句，一组SQL语句或整个程序。
①事务具有4个属性，通常称为ACID特性：原子性（atomicity），一致性（consistency），隔离性（isolation），持久性（durability）；
(2)MySQL中事务使用命令：starttransaction开启事务、Rollback回滚事务、Commit提交事务。
(3)InnoDB支持的四种事务隔离级别：
①ReadUncommitted（读取未提交）：所有的事务都可以看到其它未提交事务的执行结果，容易脏读，性能也不是太高，所以实践中很少使用；
②ReadCommitted（读取已提交）：只能看见已提交事务，是大多数数据库系统的默认隔离级别（但不是Mysql默认的）。支持不可重复度，因为同一事务的其它实例在该实例处理期间可能会有新的commit，所以同一select可能返回不同的结果；
③RepeatableRead（可重读）：MySQL的默认事务隔离级别，它确保同一事务在多个实例在并发读取数据时，会看到同样的数据行；不过理论上会导致幻读，指当用户读取某一范围的数据行时，会发现有新的“幻影”行，lnnoDB存储引擎通过多版本并发控制（MVCC，间隙锁）机制解决了该问题。（多版本解决不可重复读问题，间隙锁（并发控制）解决幻读问题）
④Serializable（串行化）：最高的隔离级别，它是在每个读的数据行上加上共享锁，通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。但在这个级别下，可能导致大量的超时现象和锁竞争；
(4)锁类型：
①全局锁：让整个库处于只读状态，常用于全库逻辑备份，Flushtableswithreadlock(FTWRL)；
②表锁：-locktables…read/write，释放：unlocktables			
③元数据锁MDL(metadatalock)：访问一个表的时候自动加上，保证读写正确性；增删改操作，加入MDL读锁；表结构更改，加入写锁；
④行锁：Innodb替代myisam的重要原因，是针对数据表中行记录的锁，锁粒度更小，提高执行效率；行锁是通过给索引上的索引项加锁来实现的，这一点与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的。所以只有通过索引条件检索数据，InnoDB才使用行级锁，否则InnoDB将使用表锁。
⑤死锁：多线程之间在并发系统中出现资源循环依赖，线程都在等待别的线程释放资源，从而进入无限等待的状态。-应对策略：
1)设置超时时间参数（默认50秒），直到超时innodb_lock_wait_timeout;
2)发起死锁检测，回滚事务，将innodb_deadlock_detect设置为on开启；
3)建议第二种；在数据库服务端控制并发，降低死锁，考虑用中间件实现，在mysql中实现就是在进入引擎前排队，这样innodb内部就不会有大量的死锁检测工作了；
⑥间隙锁（GapLock）：为解决（在InnoDB在可重复提交下）幻读问题而引入的锁机制。当使用范围条件检索数据，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但不存在的记录，叫做“间隙（GAP）”，InnoDB也会对这些间隙加锁，这种锁机制就是所谓的间隙锁。但范围内不存在的键值也会被无辜锁定，无法插入锁定范围内的任何数据，导致执行效率下降；
⑦乐观锁和悲观锁：-区别在于拿数据的时候是否认为别人会不会修改，-乐观锁认为别人不会修改，所以拿数据时候不上锁，比较适合读操作比较频繁，并发冲突少的场景。-悲观锁则认为别人会修改，所以直接上锁，比较适合写操作比较频繁，强一致性的场景，效率比较低；
⑧自旋锁：让不满足条件的线程不立即挂起，而是循环等待，通过占用处理器（CPU）的时间来避免线程切换带来的开销；
3、SQL查询：
(1)CRUD：增加(Create)、查询(Retrieve）、更新(Update)和删除(Delete)
(2)删除：droptable直接删掉表；truncatetable删除表中数据，留下表结构，在插入时自增长id又从1开始；delete删除表中数据，可以加where子句；
(3)查询：select,目标from、过滤where、分组groupby、排序orderby、限定limit、去重distinct；
(4)优化：
①尽量避免全表扫描：where子句中对字段进行null值判断；使用!=或>操作符；用or来连接条件；in和notin的使用；模糊查询前置%，都会导致全表扫描；
②用具体的字段列表代替“*”，不要返回用不到的任何字段；
③在where及orderby常涉及的列上建立索引；
④使用varchar代替char，可以节省存储空间，在一个相对较小的字段内搜索效率显然要高些；
⑤索引不要过多，索引固然可以提高相应的select的效率，但同时也降低了insert及update的效率(insert或update时有可能会重建索引)，一个表的索引数最好不要超过6个；
⑥尽量使用数字型字段，字符型会降低查询和连接的性能（引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次）；
⑦索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致。
(5)表创建三范式：
①属性不可再分：表中的字段都是单一属性，具有原子性，不可再分。
②消除冗余：-在第一范式的基础上，要求表中实例必须可以被唯一的区分，通常需要为表加上一列可以存储各个实例的唯一标识，即主键。
③消除传递依赖：满足第二范式的基础上，要求一个数据库表中不包含已在其它表中已包含的非主关键字信息。
(6)表约束：为保证插入表的数据的完整性和正确性，在创建表时，对表的一些属性进行限定；
①主键(primarykey)：是一列或多列的组合，唯一地标识表中的每一行，用与记录的修改与删除，还可与另一张表的外键关联(foreignkey)，保证数据完整性。【非空(nonull)、唯一(unique)】；
②主键自增长(keyautoincrement) 
(7)SQL注入：一种常见的网络攻击方式，它通过把SQL命令插入到Web表单提交或输入域名或页面请求的查询字符串，最终达到欺骗服务器，执行恶意的SQL命令实现无账号登录，甚至篡改数据库的目的。解决办法：对用户输入的数据进行过滤处理，对不同的字段进行条件限制，符合条件的可以写入数据库，不符合条件的进行数据过滤掉！
4、数据库优化：
(1)MySQL问题排查：
①使用showprocesslist命令查看当前所有连接信息。
②使用explain命令查询SQL语句执行计划。
③开启慢查询日志，查看慢查询的SQL。
(2)可能导致数据查询慢的原因分析：
①缓存失效，在此一段时间内由于高并发访问导致MySQL服务器崩溃；
②SQL语句编写问题；
③MySQL服务器参数问题；
④硬件配置限制MySQL服务器性能问题；
(3)优化的入手方法：
①服务层面：配置mysql性能优化参数，数据库服务器提升硬件配置，或者数据库搭建集群；
②系统层面：
1)优化数据表结构、字段类型、字段索引：（索引不是越多越好，并不是所有索引对查询都有效，当索引列有大量数据重复时，SQL查询可能不会去利用索引，如一表中有字段sex，male、female几乎各一半，那么即使在sex上建了索引也对查询效率起不了作用）		
2)分表、分库：
a.分库：当数据库中的表太多，可以考虑将表分到不同的数据库
b.分表：水平分表：将一些列分到另一张表；垂直分表：将历史信息分到另一张表中，很久之前的记录少有查询
3)读写分离：
a.通过数据库配置设置，mysql复制时，产生了多个数据副本（备库），为减少服务器压力，备库用于处理读操作，主库可同时处理读写。备库的复制是异步的，无法实时同步，读写分离的主要难点也在于备库上的脏数据。通常如果使用备库进行读，一般对数据的实时性要求不能太高。
③数据库层面：优化SQL语句，合理使用字段索引
④代码层面：使用缓存和NoSQL数据库方法存储，如MongoDB/Memcache/Redis来缓存高并发下数据库查询的压力
⑤减少数据库操作次数：尽量使用数据库访问驱动的批处理方法
⑥不常使用的数据迁移备份：避免每次都在海量数据中去检索
⑦编程手段防止SQL注入：使用JDBCPrepareStatement按位插入和查询；正则表达式过滤（非法字符串过滤）；
5、视图：
(1)包含某个查询的虚拟表，其内容由查询定义。同真实的表一样，视图包含一系列带有名称的列和行数据。
(2)通过视图用户只能查询和修改他们所能见到和有用的数据，降低数据的复杂程度；且用户可以被限制在数据的不同子集上，防止未经许可访问敏感数据，提高安全性能；
(3)临时表：借助临时表来提升查询临时效率，临时表加载于数据库内存上，使用之后就销毁；有会话临时表和全局临时表；
6、数据库连接池:
(1)（多用户的网页应用程序中）对数据库连接的管理能显著影响到整个应用程序的伸缩性和健壮性，影响到程序的性能指标。数据库连接池正是针对这个问题提出来的。
(2)数据库连接池在初始化时将创建一定数量的数据库连接放到连接池中（数量是由最小数据库连接数制约），无论这些数据库连接是否被使用，连接池都将一直保证至少拥有这么多的连接数量，当应用程序向连接池请求的连接数超过最大连接数量时，这些请求将被加入到等待队列中。
7、MVCC(多版本并发控制)：
(1)并发访问（读或写）数据库时，对正在事务内处理的数据做多版本的管理，以用来避免因写操作的堵塞引发读操作的并发问题。
(2)通过保存数据在某个时间点的快照来实现的；
(3)比锁定模型的优点是，在MVCC里对检索（读）数据的锁要求与写数据的锁要求不冲突，所以读不会阻塞写，而写也从不阻塞读。
(4)在数据库里也有表和行级别的锁定机制，用于给那些无法轻松接受MVCC行为的应用。不过，恰当地使用MVCC会提供比锁更好地性能。
8、char和varchar的区别是什么？
(1)char(n)：固定长度类型，效率高，但占用空间；适用场景：存储密码的md5值，固定长度的，使用char非常合适。
(2)varchar(n)：长度可变，存储的值是每个值占用的字节再加上一个用来记录其长度的字节的长度。
(3)从空间上考虑varcahr比较合适；从效率上考虑char比较合适，二者根据使用需要权衡。
9、float和double的区别是什么？
(1)float最多可以存储8位的十进制数，并在内存中占4字节。
(2)double最可可以存储16位的十进制数，并在内存中占8字节。
10、数据的更新方式：
(1)通知机制；
(2)用程序定时拉数据（看拉数据的间隔和执行效率）；


非关系型数据库Redis：
1、是一个基于内存的高性能Key-Value型数据库，拥有丰富的数据类型，并可实现数据持久化，并通过集群和哨兵机制实现高可用；
2、Redis集群没有使用一致性hash，而是引入了哈希槽的概念，Redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分hash槽。
3、管道（pipelining）：一次请求/响应服务器能实现处理新的请求即使旧的请求还未被响应，这样就可以将多个命令发送到服务器（将多次IO往返的时间缩减为一次），而不用等待回复（前提是pipeline执行的指令之间没有因果相关性），最后在一个步骤中读取该答复（异步）；使用redis-benchmark进行压测的时候可以发现影响redis的QPS峰值的一个重要因素是pipeline批次指令的数目。
4、Redis的五种基本数据类型：string（字符串）、hash（哈希）、list（列表），set（集合）和zset（有序集合）;
(1)string：是最简单的类型，主要用做简单的KV缓存、计数器、共享用户Session；
(2)Hash：类似 Map 的一种结构，可以将结构化的数据，比如一个对象（前提是这个对象没嵌套其他的对象）给缓存在 Redis 里，然后每次读写缓存的时候，可以就操作 Hash 里的某个字段；
(3)List：是有序列表，可以通过 List 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西，常用做：消息队列、章列表或者数据分页展示的应用；
①异步队列：使用list结构作为队列，rpush生产消息，lpop消费消息。当lpop没有消息的时候，要适当sleep一会再重试。
(4)Set：是无序集合，会自动去重，可以直接基于 Set 将系统里需要去重的数据扔进去，自动就给去重了，还可以基于 Set 执行交集、并集、差集的操作，比如交集，我们可以把两个人的好友列表整一个交集，看看俩人的共同好友是谁？两个查询一个Set搞定。	
(5)是排序的 Set，不仅可以去重还可以排序，当你需要一个有序且不重复的集合列表时，就可以选择Sortedset数据结构作为选择方案。使用场景，排行榜，带权重的队列，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。微博热搜榜，就是有个后面的热度值，前面就是名称；
①延时队列：使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理。
5、Redis中高级用户的几种数据结构HyperLogLog、Geo、Pub/Sub；
(1)-pub/sub：主题订阅者模式，可以实现1:N的简单的消息队列。但是，在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如RocketMQ等。
(2)-Pipeline：可以批量执行一组指令，一次性返回全部结果，可以减少频繁的请求应答。
(3)-Lua：Redis 支持提交 Lua 脚本来执行一系列的功能。
(4)-Bitmap：位图是支持按bit位来存储信息，可以用来实现 布隆过滤器（BloomFilter）；
(5)-HyperLogLog：供不精确的去重计数功能，比较适合用来做大规模数据的去重统计，例如统计UV；
(6)-Geospatial：可以用来保存地理位置，并作位置距离计算或者根据半径计算位置等。有没有想过用Redis来实现附近的人？或者计算最优地图路径？	
6、特点快：
(1)网络层使用多路I/O复用模型，非阻塞IO（epoll）解决高并发问题；
(2)基于内存，查找和操作的时间复杂度都是O(1)；
(3)采用单线程，避免了不必要的上下文切换和竞争条件导致的切换消耗 CPU，还不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；（单线程仅仅是说在网络请求这一模块上用一个线程处理客户端的请求，像持久化它就会重开一个线程/进程去进行处理）
①为什么是单线程：
1)单线程并不代表就慢nginx和nodejs也都是高性能单线程的代表；
2)Redis的瓶颈最有可能是机器内存或者网络带宽，cpu不是Redis的瓶颈；
(4)Redis直接自己构建了VM机制，且Redis中的数据结构是专门进行设计的；
7、支持事务：
(1)redis事务处理的基础指令：MULTI（开启）、EXEC（触发并执行）、DISCARD（放弃）、WATCH（监视）；
(2)事务中的所有命令都会序列化、按顺序地执行，在执行的过程中，不会被其他客户端发送来的命令请求所打断。
8、数据持久化：
(1)RDB（全量持久化）：周期性将redis的数据生成快照并存储，适合做冷备；
①主要通过fork和cow实现，fork是指redis通过创建子进程来进行RDB操作，cow指的是copyonwrite，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来；
②耗时，耗性能(fork+io操作)，易丢失数据（周期期间内的数据会丢失，默认五分钟甚至更久），但在数据恢复时速度比AOF快；
(2)AOF（增量持久化）：对每条写入命令以append-only的模式写入一个日志文件中，因为这个模式是只追加的方式，所以没有任何磁盘寻址的开销，所以很快；在下次重新启动时，只需把这些指令从前到后再重复执行一遍；最多丢一秒的数据，数据完整性更强，适合做热备；但体积大，恢复速度慢；
(3)官方建议两种方式同时使用，以便提供更可靠的持久化方案；Redis在重启的时候会默认使用AOF去重新构建数据，因为AOF的数据是比RDB更完整的。
(4)如果没有持久化数的需求，可以关闭RDB和AOF方式，这样redis将变成一个像memcache一样的纯内存数据库；
9、主从同步：
(1)主从同步和数据持久化的RDB和AOF有着比密切的关系。第一次同步时，主节点做一次bgsave，并同时将后续修改操作记录到内存buffer，待完成后将RDB文件全量同步到复制节点，复制节点接受完成后将RDB镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。后续的增量数据通过AOF日志同步即可（有点类似数据库的binlog）；
(2)Redis的特性就是必须支撑读高并发的，让这个master机器去写，数据同步给别的slave机器，他们都拿去读，分发掉大量的请求，而且扩容的时候还可以轻松实现水平扩容。
10、集群，实现高可用和高性能（并发）：
(1)RedisSentinal，着眼于高可用，在分布式系统中监控redis主从服务器，当master出现故障宕机时，无需人工干预即可实现故障转移，推举slave为新的master，继续提供服务，避免了对业务的影响，提高了运维工作效率。其中三个特性：1、保证高可用；2、监控各个节点；3、自动故障迁移；
①监控（Monitoring）：Sentinel会不断地检查你的主服务器和从服务器是否运作正常。
②提醒（Notification）：当被监控的某个Redis服务器出现问题时，Sentinel可以通过API向管理员或者其他应用程序发送通知。
③自动故障迁移（Automaticfailover）：当一个主服务器不能正常工作时，Sentinel会开始一次自动故障迁移操作。
④缺点：主从模式，切换需要时间丢数据，没有解决master写的压力
(2)RedisCluster，（解决单机瓶颈）使用集群的部署方式，并且是主从同步，读写分离；
①支撑N个Redismasternode，每个都可以挂载多个 slavenode。如果要支撑更大数据量的缓存，那就横向扩容更多的 master 节点，每个 master 节点就能存放更多的数据了。
②着眼于扩展性，在单个redis内存不足时，使用Cluster进行分片存储；
③集群之间通过异步复制，集群最大节点数是16384，集群目前无法做数据库选择，默认在0数据库；
④集群的主从复制模型：为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型，每个节点都会有N-1个复制品；
⑤弱一致性，Redis并不能保证数据的强一致性，这意味这在实际中集群在特定的条件下可能会丢失写操作
⑥集群不可用：假如有A，B，C三个节点的集群，在没有复制模型的情况下，如果节点B失败了，那么整个集群就会以为缺少5501-11000这个范围的槽而不可用。
(3)在Redis集群中，sentinel也会进行多实例部署，sentinel之间通过Raft协议来保证自身的高可用。
(4)RedisCluster使用分片机制，在内部分为16384个slot插槽，分布在所有master节点上，每个master节点负责一部分slot。数据操作时按key做CRC16来计算在哪个slot，由哪个master进行处理。数据的冗余是通过slave节点来保障。
11、数据淘汰，Redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略（回收策略）
(1)Redis采用主动和被动结合的失效机制，一个是和MC一样在访问时触发被动删除，另一种是定期的主动删除。
(2)key的过期时间和永久有效命令分别用：expire和persist；
(3)Redis提供6种数据淘汰策略：
①voltile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近频率最少数据淘汰
②volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
③volatile-random：从已设置过期时间的数据集（server。db[i].expires）中任意选择数据淘汰
④allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰
⑤allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰
⑥no-enviction（驱逐）：禁止驱逐数据
(4)Redis中同时使用了惰性过期和定期过期两种过期策略；
①惰性过期：只有当访问一个key时，才会判断该key是否已过期，过期则清除。（节省CPU资源，却对内存不友好，。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存）；
②定期过期：每隔一定的时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key，（该策略是前两者的一个折中方案。通过调整定时扫描的时间间隔和每次扫描的限定耗时，可以在不同情况下使得CPU和内存资源达到最优的平衡效果）；
(5)定时过期：每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。
12、对于哈希冲突问题，Redis使用链表法来解决。
13、redis分布式锁不能解决超时的问题，程序的执行如果超出了锁的超时时间就会出现问题。
(1)-Redis分布式锁其实就是在系统里面占一个“坑”，其他程序也要占“坑”的时候，占用成功了就可以继续执行，失败了就只能放弃或稍后重试。
(2)-占坑一般使用setnx(setifnotexists)指令，只允许被一个程序占有，使用完调用del释放锁
14、Redis滥用可能导致系统的不稳定、成本增高等问题，如持久化太过频繁会增大Redis服务的压力，带来Redis性能下降。其次，数据量太大、数据访问频率非常低的业务都不适合使用Redis，数据太大会增加成本，访问频率太低，保存在内存中纯属浪费资源。
15、redis内存优化，性能问题，优化：
(1)尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面，比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key,而是应该把这个用户的所有信息存储到一张散列表里面。
(2)master最好不要做持久化工作，如RDB内存快照和AOF日志文件（主服务器写内存快照，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以主服务器最好不要写内存快照）
(3)如果数据比较重要，某个slave开启AOF备份，策略设置成每秒同步一次
(4)为了主从复制的速度和连接的稳定性，master和Slave最好在一个局域网内
(5)尽量避免在压力大得主库上增加从库
(6)主从复制不要采用网状结构，尽量是线性结构，Master<--Slave1<----Slave2....
(7)使用正确的数据结构，key长度尽可能小，与sharding结合减少总内存使用；
(8)如何减少请求Redis的延迟？
①使用正确的数据结构
②分层结构可减少只读命令的latency
③总体思路是减少通信次数，因此一般情况下，尽量在redisserver一端处理好后返回结果。常用方法有：
1)有些数据结构有处理多条数据的命令，比如hmget代替多次hget
2)用pipeline代替多条命令多次与redis通信
3)用lua脚本代替pipeline、watch/multi/exec（悲观锁）等
16、加分项：
(1)结合实际应用场景来介绍缓存的使用：
①-例如调用后端服务接口获取信息时，可以使用本地+远程的多级缓存；
②对于动态排行榜类的场景可以考虑通过 Redis 的 Sortedset 来实现等等。
(2)-分布式缓存设计和使用经验：
①-项目中在什么场景使用过 Redis，使用了什么数据结构，解决哪类的问题；
②-使用MC时根据预估值大小调整 McSlab 分配参数等等。
(3)-了解缓存使用中可能产生的问题：
①-Redis 是单线程处理请求，应尽量避免耗时较高的单个请求任务，防止相互影响；
②-Redis 服务应避免和其他CPU密集型的进程部署在同一机器；或者禁用Swap内存交换，防止 Redis 的缓存数据交换到硬盘上，影响性能。再比如前面提到的MC钙化问题等等。
(4)-了解 Redis 的典型应用场景：
①-使用 Redis 来实现分布式锁；
②-使用 Bitmap 来实现 BloomFilter（使用场景最多，可以避免缓存穿透）
③-使用 HyperLogLog 来进行UV统计等等。
(5)-知道Redis4.0、5.0中的新特性：
①-支持多播的可持久化消息队列Stream；
②-通过Module系统来进行定制功能扩展。
17、关系型和非关系型数据库对比：
(1)主要区别点：
①数据存储结构，关系型数据库一般都有固定的表结构，并且需要通过DDL语句来修改表结构；非关系型数据库的存储是基于K-V的，没有固定的表结构，方便扩展；
②可扩展性，非关系型数据库则原生就支持数据的水平扩展(比如mongodb的sharding机制)，并且这可能也是很多NoSQL的一大卖点
③数据一致性：非关系型数据库一般强调的是数据最终一致性，而不没有像ACID一样强调数据的强一致性，从非关系型数据库中读到的有可能还是处于一个中间态的数据；非关系型数据库可能更多的偏向于OLAP场景，而关系型数据库更多偏向于OLTP场景
(2)非关系型Nosql（mongoDB、Redis），数据存储不需要固定的表结构，通常也不存在连接操作，通常采用hash概念及哈希函数和哈希表来组织数据。它的优点是能够进行数据的快速查询，在大数据存取上具备关系型数据库无法比拟的性能优势；
(3)关系型数据库强调ACID原则，而NoSQL数据库强调BASE原则；它减少对数据一致性支持，从而获得了基本一致性和柔和可靠性，并且利用特性达到了高可靠性和高性能，最终达到了数据的最终一致性；
(4)Cap：一致性、可用性、分区容错性；
(5)Base：基本可用、软状态和最终一致性
(6)

Linux：
内核的5个模块：
1、进程调度模块：系统调用(syscalls)是Linux内核与上层应用程序进行通信的唯一接口，
(1)系统调用的结果会在返回值中表现出来，负值为错误，0表示正确；
(2)系统调用将Linux整个体系分为用户态和内核态（内核空间和用户空间）
(3)从用户态到内核态有三种方式：系统调用、异常、外设中断；
(4)在Linux系统上，应用代码通过glibc库封装的函数，间接使用系统调用
(5)进程调度算法：
①先来先服务（FCFS）:此算法的原则是按照作业到达后备作业队列（或进程进入就绪队列）的先后次序选择作业（或进程）
②短作业优先（SJF:ShortestProcessFirst）：这种算法主要用于作业调度，它从作业后备序列中挑选所需运行时间最短的作业进入主存运行。
③时间片轮转调度算法：当某个进程执行的时间片用完时，调度程序便终止该进程的执行，并将它送到就绪队列的末尾，等待分配下一时间片再执行。然后把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。这样就可以保证队列中的所有进程，在已给定的时间内，均能获得一时间片处理机执行时间。
④高响应比优先：按照高响应比（已等待时间+要求运行时间）/要求运行时间优先的原则，在每次选择作业投入运行时，先计算此时后备作业队列中每个作业的响应比RP。选择最大的作业投入运行。
⑤优先权调度算法：按照进程的优先权大小来调度。使高优先权进程得到优先处理的调度策略称为优先权调度算法。注意：优先数越多，优先权越小。
⑥多级队列调度算法：多队列调度是根据作业的性质和类型的不同，将就绪队列再分为若干个队列，所有的作业（进程）按其性质排入相应的队列中，而不同的就绪队列采用不同的调度算法。
(6)线程调度：
①抢占式调度。依赖的是中断机制，通过中断抢回CPU执行权限然后进行调度，如Linux内核对线程的调度。
②协作式调度。需要主动让出CPU，调用调度代码进行调度，如协程，没有中断机制一般无法真正做到抢占。
(7)对于Linux调度，简单来说就是在内核态执行schedule函数，按照一定策略选出这个CPU核接下来要执行的线程，上下文切换到对应线程执行。
(8)对于用户线程调度，首先要切换到内核态，用户栈切到内核栈，在内核态调用schedule函数，选出下一个要被执行的线程，上下文切换，执行。
(9)Linux线程调度的上下文切换，主要由函数context_switch完成，主要完成相关寄存器和栈的切换，如果涉及到了进程(进程是资源管理的单位)切换，还会切换页目录进而切换进程地址空间。
(10)抢占式调度依赖的是中断机制，与Linux线程调度相比，Goroutine调度不支持抢占。不过在Go1.2后，如果goroutine涉及了函数调用，那么就可以做到一定程度的“抢占”。这个抢占式调度的原理则是在每个函数或方法的入口，加上一段额外的代码，让runtime有机会检查是否需要执行抢占度。这种解决方案只能说局部解决了“饿死”问题，对于没有函数调用，纯算法循环计算的G，scheduler依然无法抢占。
(11)死锁：在2个或多个并发进程中，如果每个进程持有某个资源而又都等待别的进程释放它们现在保持的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁。通俗地讲，就是2个或多个进程被无限期地阻塞、相互等待的一种状态。
①死锁产生的原因：系统资源不足，进程推进顺序非法
②死锁的解除和预防：对资源的分配给予合理规划，不让死锁产生的四个必要条件成立：
1)资源使用互斥：一个资源每次只能被一个进程使用；
2)资源不可剥夺：进程已获得资源，在未使用完之前，不能被其他进程强行剥夺，只能主动释放；
3)请求和保持：请求新的资源，自己的资源保持不释放状态；
4)循环等待：死锁产生的根本原因，资源循环等待，都不释放，产生死锁；
2、内存管理模块：
(1)内存是cpu和磁盘中间的缓冲层，多任务过程中可以大大提高cpu利用率；malloc()函数负责记录程序的内存申请使用情况，free()函数负责内存释放；
(2)系统启动时，操作系统将整个物理内存以4K为单位，划分为各个页。之后进行内存分配时，都以页为单位；
(3)虚拟内存：
①操作系统来说，虚拟内存就是一张张的对照表
②物理内存和进程之间的中间层，对资源进行更合理地调度，提高资源的利用率并提供和谐统一的抽象。
(4)所有的进程有各自的用户空间，但所有的进程都共享一个内核空间；
(5)内存堆栈：
①堆（二级缓存，调用速度略低）是大家共有的空间，全局堆就是所有没有分配的空间，局部堆就是用户分配的空间。堆在操作系统对进程初始化的时候分配，运行过程中也可以像系统要额外的堆，但记得用完了要还给操作系统，要不然就是内存泄露，程序结束时可能由OS回收；
②栈（一级缓存）是线程独有的，存放函数的参数值，局部变量的值等。栈在线程开始的时候初始化，每个线程的栈相互独立。每个函数都有自己的栈，栈被用来在函数之间传递参数。操作系统在切换线程的时候会自动切换栈，就是切换SS/ESP寄存器。栈空间由编译器自动分配释放；
③例如：在函数里申请了一块内存让指针指向它。实际上，这个指针的地址是在栈上，但是它所指向的内容却是在堆上面的！函数返回，函数所在的栈被销毁，指针也跟着销毁，申请的内存在堆上是不会销毁的，所以，记得释放！内存堆和数据结构中的堆是两码事，分配类似于链表。
④水满则溢，堆栈是有一定容量限制的，当超出了该容量限制，就会发生溢出；
1)操作系统会自动给每个进程分配一个最大栈空间2M，如果超过了这个上限，就会导致递归函数执行终止，所以就会报错
2)同样的，如果你创建一个数组过大，会引起堆溢出，操作系统给每个进程分配的最大堆空间是4G，如果过大会导致堆溢出。
3)解决递归函数堆栈溢出的方法就是尾递归：就是在函数返回return时调用函数本身，而不使用其他表达式。这样执行的时候尾递归函数只会占用一个栈帧，就不会引起栈溢出。
4)预防堆栈溢出需要我们在编程时了解内存使用，尽可能不要定义特别大的数组，尽可能不要定义特别复杂的函数，如多个形参等。
⑤golang的栈的动态增长的，并且是放在堆上的，理论上可以相当的大，加入循环引用就能做到人为的stackoverflow，默认栈的最大大小也就1GB，另外如果Golang编译器，或者Marshal函数能够对递归的深度做出判断，超过一定深度就报错，在栈溢出前，抛出err，避免栈溢出，程序崩溃；
3、文件系统模块：目录结构
(1)/-根目录：每一个文件和目录都从从这里开始，只有root用户具有该目录下的写权限。此目录和/root目录不同，root目录是root用户的主目录。
(2)bin–用户二进制文件：系统的所有用户使用的命令都设在这里，例如：ps，ls，ping，grep，cp等。
(3)sbin–系统二进制文件：这个目录下的linux命令通常由系统管理员使用，对系统进行维护。例如：iptable，reboot，fdisk，ifconfig，swapon命令。
(4)etc–配置文件：包含所有程序所需的配置文件。也包含了用于启动/停止单个程序的启动和关闭shell脚本。例如：/etc/resolv.conf、/etc/logrotate.conf
(5)dev–设备文件：包含设备文件，这些包括终端设备、USB或连接到系统的任何设备。例如：/dev/tty1、/dev/usbmon0
(6)proc–进程信息：是一个虚拟的文件系统，包含有关正在运行的进程的信息。例如：/proc/{pid}目录中包含的与特定pid相关的信息。
(7)var–变量文件：var代表变量文件，这个目录下是一些内容增长的文件。包括，系统日志文件(/var/log)，包和数据库文件(/var/lib)，电子邮件(/var/mail)，打印队列(/var/spool)，锁文件(/var/lock)，多次重新启动需要的临时文件(/var/tmp)；
(8)tmp–临时文件：包含系统和用户创建的临时文件。当系统重启时，这个目录下的文件都将被删除。
(9)usr–用户程序：包含二进制文件、库文件、文档和二级程序源代码。
①usr/bin中包含用户程序的二进制文件。如果你在/bin中找不到用户二进制文件，在/usr/bin目录看看。例如：atd、cron、sshd、useradd、userdel。
②usr/lib中包含了/usr/bin和/usr/sbin用到的库。
③usr/local中包含了从源安装的用户程序。例如，当你从源安装Apache，它会在/usr/local/apach2中。
(10)home–Home目录：所有用户用home目录来存储他们的个人档案。例如：/home/join、/home/nikita
(11)boot–引导加载程序文件：包含引导加载程序相关文件。内核的initrd、vmlinux、grub文件位于/boot下。
(12)lib–库：包含支持位于/bin和/sbin下的二进制文件的库文件，库文件名为id*或lib*.so.*。例如：Id-2.11.1.so，libncurses.so.5.7
(13)opt–可选的附加应用程序：-opt代表opitional；包含从个别厂商的附加应用程序。附加应用程序应该安装在/opt/或者/opt/的子目录下。
(14)mnt–挂载目录：临时安装目录，系统管理员可以挂载文件系统。
(15)media–可移动媒体设备：用于挂载可移动设备的临时目录。举例来说，挂载CD-ROM的media/cdrom，挂载软盘驱动器的/media/floppy；
(16)srv–服务数据：srv代表服务。包含服务器特定服务相关的数据，例如，/srv/cvs包含cvs相关的数据。
4、进程通信（IPC：Inter-ProcessCommunication）模块：
(1)管道（pipe）：是一种半双工的通信方式，数据只能单向流动，而且只能在有父子进程关系的进程间使用。
(2)命名管道（namedpipe）：也是半双工的通信方式，但是它允许无亲缘关系关系进程间通信。
(3)信号（signal）：用于通知接收进程某一事件已经发生，是一种比较复杂的通信方式。
(4)信号量（semophere）：主要作为进程间以及同一进程内不同线程之间的同步手段。是一个可用来控制多个进程对共享资源访问的计数器。它通常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。
(5)消息队列（messagequeue）:是由消息组成的链表，存放在内核中，并由消息队列标识符标识。消息队列克服了信号传递消息少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。
(6)共享内存（sharedmemory）:就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问，共享内存是最快的IPC方式，它是针对其他进程间的通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量等配合使用，来实现进程间的同步和通信。
(7)套接字（socket）：套接口也是进程间的通信机制，与其他通信机制不同的是它可用于不同及其间的进程通信。
(8)进程通信几种方式的比较：
①管道：速度慢、容量有限
②消息队列：容量收到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题。
③信号量：不能传递复杂信息，只能用来同步。
④共享内存：能够很容易控制容量，速度快，但要保持同步，比如一个进程在写的时候，另一个进程要注意读写的问题，相当于线程中的线程安全。
(9)线程间通信：目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制；
①锁机制：
1)互斥锁：以排它方式防止数据结构被并发修改；
2)条件变量：始终与互斥锁一起使用，对条件的测试是在互斥锁的保护下进行的，条件变量可以以原子的方式进行阻塞进程，直到某个特定条件为真为止；
3)读写锁：允许多个线程同时读共享数据，而对写操作是互斥的；
②信号量机制：包括无名信号量和命名线程信号量
③信号机制：类似进程间的信号处理
(10)进程和线程：进程和线程的主要差别在于它们是操作系统对资源管理的不同方式。进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的一个实例。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。对于一些要求同时进行并且又要共享某些变量的并发操作，只能用线程，不能用进程。
(11)多线程：提高系统资源利用率，对于一些比较耗时和等待的操作（数据查询，网页响应，爬取网页），使用多线程，处理器就可以在某个线程等待的时候，去执行其他的线程，从而从整体上提高执行效率。计算密集型不建议使用多线程，衡量的标准就是，线程切换增加的额外开销要小于该线程能够消除的阻塞时间，才叫物有所值。
①线程锁：在一个进程中的多个线程是共享资源的，线程加锁通过确保同一时间只有一个线程操作共享内存中的数据，解决多线程并发情况下的数据访问安全问题。
②线程池：类似于消息队列的消息异步处理，只要我们的系统之间交互不是强一致性的，又希望提高系统的吞吐量，我们就可以考虑使用线程池，常用于多任务同时触发，并可能某些任务执行时间过长，请求可能会被阻塞住的线程；
(12)协程：操作系统可以进行线程和进程的调度，本身具备并发能力，但进程的调度切换需要保存现场，耗费太多时间，代价高昂。Go语言并发就是基于这个思想使得应用程序在用户层再构建一级调度，将并发的粒度进一步降低。
①协程的切换则是由用户控制的，而线程的切换是由操作系统控制的；
②goroutine类似于”守护线程“，异步执行的,如果主goroutine不等待片刻，可能程序就没有输出打印了。
(13)线程锁: 主要用来给方法、代码块加锁。当某个方法或者代码块使用锁时，那么在同一时刻至多仅有一个线程在执行该段代码。当有多个线程访问同一对象的加锁方法 / 代码块时，同一时间只有一个线程在执行，其余线程必须要等待当前线程执行完之后才能执行该代码段。 但是，其余线程是可以访问该对象中的非加锁代码块的。 　　
(14)进程锁: 也是为了控制同一操作系统中多个进程访问一个共享资源，只是因为程序的独立性，各个进程是无法控制其他进程对资源的访问的， 但是可以使用本地系统的信号量控制（操作系统基本知识）。
5、网络接口模块：Unix（like）中，一切皆文件。
(1)Socket、FIFO、管道、终端都是文件，一切都是流。在信息交换的过程中，实际都是对这些流进行的数据收发操作，简称I/O操作（系统调用read、write）。而流有很多，于是就用文件描述符（fd）来区分具体是哪个流。例如，我们创建了一个socket（网络io），系统调用会返回一个fd，对socket的任何操作都是对这个fd的操作（隐隐包含着一种分层与抽象的思想）；
(2)IO发生时（以networkI/Oread为例）涉及到两个系统对象：一个是调用这个IO的process（进程）或者thread（线程），一个是kernel系统内核；以及两个阶段（交互过程）：1、等待数据准备，2、将数据从内核copy到process中。IO模型的区别就是在这两个阶段上的差异。
①blocking（阻塞）IO：用户进程发起调用后，整个进程就会被阻塞，等待kernel进行数据准备，并将数据从系统内存copy到用户内存，然后kernel返回结果，进程接触阻塞状态（blockingIO的特点就是两个阶段都被block）；
②non-blocking（非阻塞）IO：用户进程发起操作，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error，用户进程就知道数据还没有准备好，于是就周期再发送read调用，直到kernel中数据准备好，再次接收到systemcall后，将数据copy到用户内存（这种模型效率很低）
③multiplexing（多路复用）IO：和blockingio差别不大，但它有两个systemcall，所以还更差一些，但是它可以处理多个connection，能处理更多连接：
1)其实就是select/epoll，也称为eventdriven（事件驱动）IO。
2)select/epoll的好处就是一个thread可以同时处理多个socket的IO，其基本原理就是select/epoll会不断轮询所负责的socket，当某个socket有数据到达了，就通知用户进程。当用户进程调用了select/epoll，整个进程就会被block，同时kernel会observe所有select/epoll负责的socket，任何一个socket中数据准备好之后，select/epoll就会返回，这时用户进程再调用readsystemcall，将数据从kernelcopy进用户内存。
④asynchronous（异步）IO：发起操作后，可以直接开始做其它事；从kernel的角度，当它收到一个异步io操作之后，首先会立刻返回，不会对用户进程产生任何block。然后会等待数据准备完成并将数据拷贝到用户内存中，完成之后kernel会给用户进程发送一个signal，告诉它read操作完成了。
1)阻塞和非阻塞是一种调用机制，只涉及到调用方（针对单个进程的执行状态），调用方等待IO操作完成后返回则为阻塞，无需等待IO操作完成便返回则为非阻塞（非阻塞的情况下，调用方常常需要主动去check，获得IO的操作结果）；
2)同步与异步是一种通信机制，涉及到调用方和被调用方（针对应用程序与内核而言）；同步过程中，进程触发IO操作并等待（阻塞）或者轮询的（非阻塞）去查看IO操作是否完成；异步过程中，进程触发IO操作以后，直接返回，做自己的事情，IO交给内核来处理，完成后内核通知进程IO完成。
3)同步和异步关注的是程序之间的协作关系。同步分为阻塞和非阻塞，异步则只有非阻塞。
⑤signaldriven（信号驱动）IO：
(3)多路复用：select、poll、epoll 模型的区别?
①select本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理。 这样所带来的缺点是：1、单个进程可监视的fd数量被限制；2、需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大；3、对socket进行扫描时是线性扫描。
②poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历， 如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。 它没有最大连接数的限制，原因是它是基于链表来存储的，但是同样有一个缺点：大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义。 poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。
③epoll支持水平触发和边缘触发，最大的特点在于边缘触发，它只告诉进程哪些fd刚刚变为就需态，并且只会通知一次。 在前面说到的复制问题上，epoll使用mmap减少复制开销。 还有一个特点是，epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd， epoll_wait便可以收到通知。
6、LVS（LinuxVirtualServer），Linux虚拟服务器：
(1)主要用于多服务器的负载均衡。它工作在网络层，可以实现高性能，高可用的服务器集群技术。它廉价，可把许多低性能的服务器组合在一起形成一个超级服务器。它易用，配置非常简单，且有多种负载均衡的方法。它稳定可靠，即使在集群的服务器中某台服务器无法正常工作，也不影响整体效果。另外可扩展性也非常好。	
①LVS集群为三层结构:
1)负载调度器(loadbalancer)：这是LVS的核心部分，它好比我们网站MVC模型的Controller。它负责将客户的请求按照一定的算法分发到下一层不同的服务器进行处理，自己本身不做具体业务的处理。另外该层还可用监控下一层的状态，如果下一层的某台服务器不能正常工作了，它会自动把其剔除，恢复后又可用加上。该层由一台或者几台DirectorServer组成。
2)服务器池(serverpool)：一组真正执行client请求的服务器，一般是我们的web服务器；除了web，还有FTP，MAIL，DNS。
3)共享存储(sharedstorage)：它为serverpool提供了一个共享的存储区，很容易让服务器池拥有相同的内容，提供相同的服务。主要是提高上一层数据和为上一层保持数据一致。
(2)Namespace：是linux内核用来隔离内核资源，对全局系统资源的一种封装隔离，为docker等容器技术的出现和发展提供了基础条件；
①处于不同Namespace的进程拥有独立的全局系统资源（改变一个namespace中的系统资源只会影响当前namespace里的进程，对其他namespace中的进程没有影响）
②只有在同一个namespace下的进程可以感知彼此的变化，而对其它namespace中的进程一无所知；
③proc/[pid]/ns目录下会包含进程所属的namespace信息，命令：
1)通过clone()在创建新进程的同时创建namespace
2)通过setns()函数可以将当前进程加入到已有的namespace中
3)通过unshare函数可以在原进程上进行namespace隔离；
(3)CGroup：最初的目标是用来限制、控制与分离一个进程组的资源（CPU、内存、磁盘输入输出等），既整合现有的cpuset等子系统，也为未来开发新的子系统提供接口。现在的cgroups适用于多种应用场景：单个进程的资源控制，实现操作系统层次的虚拟化（OSLevelVirtualization）；功能：
①限制进程组可以使用的资源数量（Resourcelimiting），一旦进程组使用的内存达到限额再申请内存，就会触发OOM（outofmemory）；
②进程组的优先级控制：可以使用cpu子系统为某个进程组分配特定cpushare；
③记录进程组使用的资源数量（Accounting）：记录某个进程组使用的cpu时间；
④进程组隔离（Isolation）：使用ns子系统可以使不同的进程组使用不同的namespace，以达到隔离的目的，不同的进程组有各自的进程、网络、文件系统挂载空间；
⑤程组控制（Control）：使用freezer子系统可以将进程组挂起和恢复。
7、使用和命令操作：
(1)vi/vim：具有程序编辑能力的文本编辑器，具有代码补全、编译及错误跳转等便于编辑的功能；Unix系统都会内建vi文书编辑器；
①进入vi/命令模式：vi/vimfilename；由命令模式进入输入编辑模式：按键ioa;
②编辑模式完成进入底线模式，并保存退出：输入模式下，Esc键+":"，存修改文件退出：":wq"；
(2)shell：是Unix操作系统下传统的用户和计算机的交互界面，也是控制系统的脚本语言。
①bash是众多shell版本中的一种，不同的shell版本对应这不同的需求，没有好坏，在Linux中默认的shell就是Bourne-Againshell(简称bash)，另外一个是伯克利分校比尔▪乔伊写的CShell(csh)，因为类似C语言，故此得名。而由这两种又发展出很多其它的版本，不过根基都在这里。
②可以用shell脚本实现一些常用的功能，可以提高工作效率。
(3)常用命令：
①安装：apt-getinstall/update；清屏：clear；
②日期：data；日历：cal；关机：shoutdown；重启：rebote；
③系统管理/监控：
1)uname-显示系统信息/内核版本；ps-查看进程统计信息；ipaddr-查看ip地址；
2)vmstat-显示虚拟内存状态；ulimit-显示系统资源限制的信息；df-显示磁盘空间使用情况；lsblk-查看系统的磁盘
3)tftp-上传及下载文件；ftpwho-显示ftp会话信息；curl-文件传输工具；fsck-检查并修复Linux文件系统
4)free-查看内存额的专用工具命令，显示系统中物理上的空闲/已用内存，交换内存，以及被内核使用的缓冲和缓存
5)top-查看系统进程，显示系统内存；实时动态地查看系统的整体运行情况，是一个综合了多方信息检测系统性能和运行信息的实用工具
④文件管理/编辑：
1)pwd-显示文件路径；ls-显示指定工作目录下的内容及属性信息；
2)mkdir-创建目录；rmdir-删除空目录
3)cp-复制文件或目录；rm-移除文件或目录；mv-移动或改名文件
4)cat-在终端设备上显示文件内容；tail-查看文件尾部内容
5)echo-输出字符串或提取Shell变量的值
⑤网络通信：
1)ssh-安全连接客户端
2)ping-测试主机间网络连通性
3)netstat-显示网络状态，用于监控进出网络的包和网络接口统计的命令行工具；
4)ifconfig-显示或设置网络设备
5)ss-显示活动套接字信息
6)servicenetworkrestart-重启网络
8、常用工具：
(1)w：查看到当前登录系统的用户是谁，以及执行了哪些命令。
(2)nmon：监控系统性能的小工具，nmon可以查看网络、CPU、内存和磁盘的使用情况。
①使用之前需要先用如下命令进行安装：sudoapt-getinstallnmon
②安装好后执行nmon命令即可打开：里面有对应查看信息属性的对应命令操作；如，打开之后按c查看CPU信息，按n查看网络信息；
(3)dstat：用于监控内存、进行、网络及磁盘性能，可用于替代ifstat、iostat、dmstat等工具。
①使用之前需先执行如下命令进行安装：apt-getinstalldstat
②执行dstat命令可以看到所有监控数据，其可选参数非常多，常用的有：
1)dstat-c：监控CPU
2)dstat-cdl-Dsda1：监控CPU详细信息
3)dstat-d：监控磁盘
9、Ctrl+c暂停命令/程序执行；
10、SSH：SecureShell（安全外壳），是建立在应用层基础上的安全协议；
(1)正确使用时可弥补网络中的漏洞，有效防止远程管理过程中的信息泄露问题；
(2)网络服务程序（ftp、pop和telnet）在网络上用明文传送口令和数据，非常容易就可以截获这些口令和数据，而且这些服务程序的安全验证方式也是有其弱点的，中间人”可以冒充真正的服务器接“收你传给服务器的数据，然后再冒充你把数据传给真正的服务器，中转过程数据可能会被做手脚；
(3)使用SSH，可以把所有传输的数据进行加密，还有一个额外的好处就是传输的数据是经过压缩的，加快传输的速度；
(4)SSH是由客户端和服务端的软件组成的，有两个不兼容的版本分别是：1.x和2.x；
(5)SSH提供两种级别的安全验证：
①基于口令的安全验证，传输的数据都会被加密，但是不能保证你正在连接的服务器就是你想连接的服务器；
②基于密匙的安全验证：自己创建一对密匙，并把公用密匙放在需要访问的服务器上，请求，公钥验证，私钥质询。
③与第一种级别相比，第二种级别不需要在网络上传送口令，第二种级别不仅加密所有传送的数据，而且“中间人”这种攻击方式也是不可能的（因为他没有你的私人密匙）。但是整个登录的过程可能需要10秒。
11、SSL：是一种国际标准的加密及身份认证通信协议；
(1)SSL协议使用通讯双方的客户证书以及CA根证书，允许客户/服务器应用以一种不能被偷听的方式通讯，在通讯双方间建立起了一条安全的、可信任的通讯通道。
(2)具基本特征：信息保密性（数据封装）、信息完整性（掉包拒收）、相互鉴定（身份校验）；
(3)HTTPS：协议是由HTTP加上TLS/SSL协议构建的可进行加密传输、身份认证的网络协议，主要通过数字证书、加密算法、非对称密钥等技术完成互联网数据传输加密，实现互联网传输安全保护；、
12、Linux发行版，是指一些企业采用某种办法把linux内核、Glibc库、硬件驱动模块以及各种应用软件打包集成在一起，以光盘或者镜像文件的形式交付给用户安装使用；
13、Linux软链接和硬链接
(1)- 硬链接： ln link source，Linux文件系统给磁盘分区中的所有文件都会分配一个称为索引节点号（Inode Idnex）的编号，在Linux中，多个文件名指向同一索引节点是存在的。一般这种连接就是硬连接。硬连接的作用是允许一个文件拥有多个有效路径名，以防止“误删”的功能。因为只要对应该目录的索引节点有一个以上的连接，只有当最后一个连接被删除后，文件的数据块及目录的连接才会被释放。
(2)软链接： ln -s slink source，也称为符号连接（Symbolic Link），软链接文件类似于Windows的快捷方式。它实际上是一个包含另一文件的位置信息的特殊的文本文件。
14、孤儿进程，僵尸进程
(1)孤儿进程：父进程退出，子进程还在运行的程序称为孤儿进程。孤儿进程会被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。
(2)僵尸进程：子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中，这种进程称之为僵死进程。


网络编程：
1、通过操作相应的API调度计算机资源硬件，并且利用管道（网线）进行数据交互的过程；
2、七层网络模型——OSI（OpenSystemInterconnection，开放式系统互联）：
(1)基础层：
①物理层（physical）：主要规定了一些电气特性，负责传送0和1的电信号；
②数据链路层（Datalink）：规定0和1电信号的分组方式，例如以太网（Ethernet)协议，以“帧”（Frame）的形式传输数据；帧分：标头（Head）和数据（Data），“数据”的长度，最短为46字节，最长为1500字节。如果数据过长，就必须分割成多个帧进行发送；
③网络层（network）：帮助我们确定计算机所在的子网络，网络层有IP协议、ICMP协议、ARP协议、RARP协议和BOOTP协议。IP数据包总长度最大为65535字节；
(2)传输层（Transport）：TCP/UDP协议层
①端口：有了IP和端口才能唯一确定互联网上的一个程序，进而实现网络间的程序通信；端口是0到65535之间的一个整数（16个二进制位）。0到1023的端口被系统占用，用户只能选用大于1023的端口；
②TCP面向连接，提供可靠的通信服务（有验证重发机制），点对点的通信；
1)会粘包，
2)过程复杂、实现困难、消耗较多的资源；
③UDP是无连接的，面向报文的，不可靠的简单通信；特点是：
1)开销少，UDP的首部8个字节，TCP20字节，总长度不超过65,535字节，正好放进一个IP数据包；
2)没有拥塞控制，网络不会出现拥塞使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等）；
3)可以一对一，一对多，多对多交互通信
(3)高级层：会话层（Session）、表示层（Presentation）、应用层（Application）
①互联网是开放架构，数据来源繁杂，“应用层”的作用就是规定应用程序使用的数据格式，例如我们TCP协议之上常见的Email、HTTP、FTP、TELNET、STMP、DNS等协议，这些协议就组成了互联网协议的应用层。
(4)网络经典的五层协议体系结构：物理层、数据链路层、网络层、传输层、应用层；
(5)TCP/IP模型四个层次：应用层，传输层，网络层，网络接口层；
3、Socket：
(1)是UNIX的进程通信机制，也称作“套接字”，用于描述IP地址和端口这一组合，是应用层与TCP/IP协议族通信的中间软件抽象层，开发者只需要调用Socket规定的相关函数，就能让Socket去组织指定的协议然后进行数据通信；
(2)Socket类型有两种：基于TCP协议的流式套接字（Stream_Socket），基于UDP协议的数据报式套接字(Datagram_Socket)

(3)TCP编程的服务器端一般步骤是： 　　
①创建一个socket，用函数socket()；
②设置socket属性，用函数setsockopt();可选　　
③绑定IP地址、端口等信息到socket上，用函数bind();
④开启监听，用函数listen()；
⑤接收客户端上来的连接，用函数accept()；
⑥收发数据，用函数send()和recv()，或者read()和write();
⑦关闭网络连接；closesocket(SocketListen)，closesocket(SocketWaiter);
⑧关闭监听；
(4)TCP编程的客户端一般步骤是： 　　
①创建一个socket，用函数socket()；　　
②设置socket属性，用函数setsockopt();*可选　　
③绑定IP地址、端口等信息到socket上，用函数bind();*可选　　
④设置要连接的对方的IP地址和端口等属性；　　
⑤连接服务器，用函数connect()；　　
⑥收发数据，用函数send()和recv()，或者read()和write();　　
⑦关闭网络连接；
(5)使用tcp发生粘包：
①由TCP协议本身造成的，TCP为提高传输效率，发送方往往要收集到足够多的数据后才发送一包数据；接收方接受数据不及时，把收到的数据放在系统接收缓冲区，而用户进程根据预先设定的缓冲区大小从系统接收缓冲区取数据，这样就一次取到了多包数据，也会产生粘包；
②解决办法：对数据包进行封包和拆包的操作，自定义一个协议，比如数据包的前4个字节为包头，里面存储的是发送的数据的长度。
4、序列化和反序列化的过程就是生成和解析字符的过程，通过序列化，
(1)实现数据的持久化，将数据保存到磁盘上；
(2)在网络上实现远程通信；
5、同步和异步、阻塞和非阻塞：
6、
	
	
同步和异步：是针对应用程序和操作系统内核的交互而言，关注的是任务完成时的消息通知机制，应用程序等待或者轮询的向内核询问，则是同步方式；应用程序无须去向系统内核询问，在内核读取完数据之后会主动通知应用，则为异步；
阻塞和非阻塞：关注的是应用程序发出请求后等待数据返回时的状态，如果等待过程中程序挂起，一直处于等待返回的状态，则为阻塞；相反，系统内核会立即返回(虽然还没有数据)，但是应用程序并不会挂起，可以去做其它的事情，则为非阻塞；


缓存：
1、想提高系统的性能，尽量减少IO的操作，特别是磁盘IO的操作；使用缓存可以有效的避免这种情况；所以在架构设计过程中，社交到查询数据库的时候，应该考虑一下是不是考虑使用缓存技术来提高系统的性能，并且降低数据库的负载。缓存就是通过在本地磁盘内保存的资源副本，减少对源服务器的访问，节省通信流量和通信时间，提高系响应速度和用户体验；
2、缓存分类：
(1)本地缓存：是内存访问，没有远程交互开销，性能最好，但是受限于单机容量，一般缓存较小且无法扩展；
(2)分布式缓存：解决单机容量限制，分布式缓存一般都具有良好的水平扩展能力，对较大数据量的场景也能应付自如。缺点就是需要进行远程请求，性能不如本地缓存；
①目的：解决数据库服务器和web服务器之间的瓶颈。
②如果一个网站的流量很大，这个瓶颈将会非常明显，每次数据库查询耗费的时间将会非常可观。对于更新速度不是很快的网站，我们可以用静态化来避免过多的数据库查询。对于更新速度以秒计的网站，静态化也不会太理想，可以用缓存系统来构建。如果只是单台服务器用作缓存，问题不会太复杂，如果有多台服务器用作缓存，就要考虑缓存服务器的负载均衡。
③使用Memcached分布式缓存服务来达到保存用户的会话数据，而达到各个功能模块都能够跨省份、跨服务器共享本次会话中的私有数据的目的。每个省份使用一台服务器来做为Memcached服务器来存储用话的会话中的数据，当然也可以多台服务器，但必须确保每个省份的做Memcached服务器数量必须一致，这样才能够保证Memcached客户端操作的是同一份数据，保证数据的一致性。
(3)多级缓存：平衡本地和分布式缓存缺点，实际业务中一般采用多级缓存，本地缓存只保存访问频率最高的部分热点数据，其他的热点数据放在分布式缓存中（最常用的缓存方案，单靠单一的缓存方案往往难以撑住很多高并发的场景）
3、MongoDB：
(1)旨在为WEB应用提供可扩展、高性能的分布式数据存储解决方案；
(2)通过计算机网络与节点相连，服务端默认端口为27017，在32位模式运行时支持的最大文件尺寸为2GB，推荐运行在64位平台。
(3)支持对数据建立索引，可以实现类似于关系数据库的单表查询的绝大部分功能，类似于面向对象的查询语言；
(4)面向集合存储，使用高效的二进制数据存储（包括大型对象（如视频等）），文件存储格式为BSON（一种JSON的扩展）
(5)文档是MongoDB中数据的基本单位，类似于关系型数据库中的行（但比行复杂）；集合是一组文档，类似于关系型数据库中的表，集合是无模式的，集合中的文档可以是各式各样的；数据库：多个文档组成集合，多个集合组成数据库。
(6)MongoDB中存在以下系统数据库：
①Admin数据库：权限数据库，创建用户时将该用户添加到此数据库中，就自动继承了所有数据库的权限；
②Local数据库：这个数据库永远不会被复制，可以用来存储本地单台服务器的任意集合；
③Config数据库：当MongoDB使用分片模式时，config数据库在内部使用，用于保存分片的信息；
(7)使用场景：
①网站数据：Mongo非常适合实时的插入，更新和查询，并具备网站实时数据存储所需的复制及高度伸缩性；
②缓存：由于性能很高，Mongo也适合作为信息基础设施的缓存层。
③用于大尺寸，低价值的数据存储：在此之前，很多时候程序员往往会选择使用传统的关系型数据库存储一些数据，代价可能会比较昂贵；
④高伸缩性的场景：Mongo非常适合由数十或数百台服务器组成的数据库，Mongo的路线图中已经包含对MapReduce引擎的内置支持；
⑤用于对象及JSON数据的存储：Mongo的BSON数据格式非常适合文档化格式的存储及查询； 
4、redis：
(1)丰富的特性(基于丰富的数据类型)、消息队列、支持事务、数据持久化、存在内存查找和操作hashmap的时间复杂度都是0；
(2)Redis提供主从同步机制，以及 Cluster 集群部署能力，能够提供高可用服务；
(3)
5、Memcache：
(1)当容量存满时，会对缓存中的数据进行剔除，剔除时除了会对过期key进行清理，还会按LRU策略对数据进行剔除。
(2)key不能超过250个字节，最大失效时间是30天；value不能超过1M字节；只支持K-V结构，不提供持久化和主从同步功能，这些限制是现在互联网场景下大家选择Redis、MongoDB的重要原因；
(3)MC处理请求时使用多线程异步IO的方式，可以合理利用CPU多核的优势，性能非常优秀；比redis还快；
6、总结：
(1)redis更适用于较小数据量的性能及运算，mongodb则在海量数据的访问下性能更优，且二者均支持持久化；
(2)memcache使用多线程，主线程监听，worker子线程接受请求，执行读写，这个过程可能存在锁冲突。redis使用的单线程，虽然无锁冲突，但是难以利用多核的特性提升吞吐量；
(3)memcache和redis都使用非阻塞的IO复用模型；
(4)memcache的内存分配采用的是预分配内存池的管理方式，能够省去内存分配的时间，redis是临时申请空间，可能导致碎片化；
(5)memcache将所有的数据存储在物理内存里，redis有自己的vm机制，理论上能够存储比物理内存更多的数据，当数据超量时，引发swap，把冷数据刷新到磁盘上，从这点上，数据量大时，memcache更快：
7、顺序消费：
(1)对系统并发带来的问题，网络抖动，本该首先执行的操作，落在了最后；
(2)多系统实例，同时去更新某个key，每个系统通过Zookeeper获取分布式锁，确保同一时间，只能有一个系统实例在操作某个Key，别人都不允许读和写。
(3)数据写入MySQL的时候，保存一个时间戳，每次要写入缓存之前，先判断一下当前这个Value（数据库中取的value）的时间戳是否比缓存里的Value的时间戳要新。如果是的话，那么可以写，否则，就不能用旧的数据覆盖新的数据。
8、热点问题，首页缓存容易出现的三个问题：
(1)缓存雪崩：同一时间缓存大面积失效，大量请求直接打到数据库，如果没做熔断等策略，相关联服务会是瞬间挂一片的节奏，重启也会立即被打卦；
①使用快速失败的熔断策略，减少DB瞬间压力；
②Redis是集群部署，将热点数据均匀分布在不同的Redis库中也能避免全部失效的问题；
③避免缓存大量缓存同一时刻失效，在key值失效上再加一个随机数字；
(2)缓存击穿：是单一热点数据的突然失效，持续的大并发就穿破缓存，直接请求数据库；
①置热点数据永远不过期；
②使用随机退避方式，失效时随机sleep一个很短的时间，再次查询，如果失败再执行更新。
③异步加载，对这部分热点数据采取到期自动刷新的策略；
④使用互斥锁更新，保证同一个进程中针对同一个数据不会并发请求到DB，减小DB压力。
(3)缓存穿透：意的请求会故意查询不存在的key，浪费后端系统查询性能；
①在接口层增加校验（用户鉴权校验，参数校验），不合法的参数直接代码Return；
②对单个IP每秒访问次数超出阈值的IP拉黑，查询结果为空的情况也进行缓存，；对一定不存在的key进行过滤；
③Redis的一个高级用法布隆过滤器（BloomFilter），也能很好的防止缓存穿透的发生，它利用高效的数据结构和算法快速判断出你这个Key是否在数据库中存在，不存在你return就好了，存在就去查了DB刷新KV再return。
(4)总结：一般避免以上情况发生我们从三个时间段去分析下：
①事前：Redis高可用，主从+哨兵，Rediscluster，避免全盘崩溃。
②事中：本地ehcache缓存+Hystrix限流+降级，避免MySQL被打死。
③事后：Redis持久化RDB+AOF，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。
④限流组件，可以设置每秒的请求，有多少能通过组件，剩余的走降级！可以返回一些默认的值，或者友情提示，或者空白的值。（确保每秒有多少个请求通过，保证数据库不死）；
9、数据淘汰策略：不管是本地缓存还是分布式缓存，为了保证较高性能，都是使用内存来保存数据，由于成本和内存限制，当存储的数据超过缓存容量时，需要对缓存的数据进行剔除。数据淘汰算法：
(1)LRU（Leastrecentlyused），最近最少使用，淘汰最后被访问时间最久的元素。
①设计原则：如果一个数据在最近一段时间没有被访问到，那么在将来它被访问的可能性也很小；
②最常见的实现是使用一个链表保存缓存数据；
③缺点：可能会由于一次冷数据的批量查询而误导大量热点的数据；
(2)LFU(LeastFrequentlyUsed)：淘汰最近访问频率最小的元素：
①最新加入的数据常常会被踢除，因为其起始方法次数少；
②如果频率时间度量是1小时，则平均一天每个小时内的访问频率1000的热点数据可能会被2个小时的一段时间内的访问频率是1001的数据剔除掉
10、删除缓存，而不是更新缓存；
(1)在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值，例如可能是更新字段的运算值；
(2)更新的缓存不一定被访问，白白浪费系统的性能去更新它，而是在被使用的时候再去重新计算；
(3)例如：一个缓存涉及的表的字段，在1分钟内就修改了20次，或者是100次，那么缓存更新20次、100次；但是这个缓存在1分钟内只被读取了1次，有大量的冷数据，而删除缓存的话，那么在1分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低；
11、数据一致性问题：
(1)数据库数据的实时更新：
①数据库支持通知机制，数据库某表发生变化自动通知前台，数据库自动推送数据；
(2)缓存与数据库双写，如何解决一致性问题：
①串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低；
②把一些列的操作都放到队列里面，顺序肯定不会乱，但是并发高了，这队列很容易阻塞，反而会成为整个系统的弱点，瓶颈；
(3)最经典的KV、DB读写模式：CacheAsidePattern
①读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。更新的时候，先更新数据库，然后再删除缓存。
(4)缓存和数据库数据不一致，
①加入了缓存之后，主从不一致的时间被拉长；
②在从库有数据更新之后，将缓存当中的数据也同时进行更新，即当从库发生了数据更新之后，向缓存发出删除，淘汰这段时间写入的旧数据。
③如果服务对耗时不是特别敏感可以增加重试；
④如果服务对耗时敏感可以通过异步补偿任务来处理失败的更新，或者短期的数据不一致不会影响业务，那么只要下次更新时可以成功，能保证最终一致性就可以。
12、



消息队列：
1、使用消息队列的目的：解耦，异步，削峰：
(1)在高并发分布式环境下，由于来不及同步处理，请求（比如大量的insert、update之类的请求）往往发生堵塞，当请求同时到达数据库，直接导致无所的行锁和表锁，甚至最后请求会堆积过多，从而触发too many connections错误，通过使用消息队列，我们可以异步处理请求，从而缓解系统的压力。
(2)ACK机制-当消费者拿到消息的瞬间，队列中的消息立即删除。同时删除前台页面，缓存库，数据库 (ACK机制保证了性能的高效.)
2、使用消息队列会出现什么问题：
(1)降低系统可用性：本来系统正常，加入消息队列，万一消息队列挂了，整个系统可能都会受牵连，因此，系统可用性会降低
(2)增加系统复杂性：加入了消息队列，要多考虑，一致性问题、消息不被重复消费问题、保证消息可靠性传输，顺序消费等问题，考虑的东西更多，系统复杂性更大。
3、技术选型：RocketMQ（功能完备，扩展性佳）和kafka（多用于大数据领域）分布式架构（高可用）；
4、RabbitMQ：是一个在AMQP基础上完整的，可复用的企业消息系统；
(1)AMQP(高级消息队列协议) ：是一个异步消息传递所使用的应用层协议规范，作为线路层协议，而不是API（例如JMS），AMQP 客户端能够无视消息的来源任意发送和接受信息。主要有四个概念：
①virtual host，虚拟主机：在RabbitMQ当中，用户只能在虚拟主机的粒度进行权限控制。因此，如果需要禁止A组访问B组的交换机/队列/绑定，必须为A和B分别创建一个虚拟主机。每一个RabbitMQ服务器都有一个默认的虚拟主机。
②exchange，交换机：负责把一个消息放进队列前，可以理解成具有路由表的路由程序。每个消息都有一个称为路由键（routing key）的属性，就是一个简单的字符串。交换机当中有一系列的绑定（binding），即路由规则（routes）。（例如，指明具有路由键 “X” 的消息要到名为timbuku的队列当中去。）
③queue，队列：装消息的容器，由消费者（Consumer）通过程序建立的，不是通过配置文件或者命令行工具。这没什么问题，如果一个消费者试图创建一个已经存在的队列，RabbitMQ会直接忽略这个请求。因此我们可以将消息队列的配置写在应用程序的代码里面。
④binding，绑定：交换机如何判断要把消息送到哪个队列。你需要路由规则，即绑定（binding）。一个绑定就是一个基于路由键将交换机和队列连接起来的路由规则；例如，具有路由键“audit”的消息需要被送到两个队列，“log-forever”和“alert-the-big-dude”。要做到这个，就需要创建两个绑定，每个都连接一个交换机和一个队列，两者都是由“audit”路由键触发。在这种情况下，交换机会复制一份消息并且把它们分别发送到两个队列当中。交换机不过就是一个由绑定构成的路由表。
(2)分布式集群架构和高可用性：提供节点崩溃额情况下的继续可用（高可用）和扩展消息通信的吞吐量；RabbitMQ可以通过三种方法来部署分布式集群系统，分别是：cluster，federation，shovel：
①cluster：支持跨网段，用于同一个网段内的局域网，可以随意的动态增加或者减少，节点之间需要运行相同版本的RabbitMQ和Erlang；
1)RabbitMQ cluster 集群的两种模式：普通模式（默认的集群模式）；镜像模式，把需要的队列做成镜像队列，存在于多个节点，属于RabbitMQ的HA方案
②federation：应用于广域网，允许单台服务器上的交换机或队列接收发布到另一台服务器上交换机或队列的消息，可以是单独机器或集群。federation队列类似于单向点对点连接，消息会在联盟队列之间转发任意次，直到被消费者接受。通常使用federation来连接internet上的中间服务器，用作订阅分发消息或工作队列。
③shovel：连接方式与federation的连接方式类似，但它工作在更低层次。可以应用于广域网
(3)RabbitMQ集群会始终同步四种类型的内部元数据（类似索引）：
①队列元数据：队列名称和它的属性；
②交换器元数据：交换器名称、类型和属性；
③绑定元数据：一张简单的表格展示了如何将消息路由到队列；
④vhost元数据：为vhost内的队列、交换器和绑定提供命名空间和安全属性；因此，当用户访问其中任何一个RabbitMQ节点时，通过rabbitmqctl查询到的queue／user／exchange/vhost等信息都是相同的。
1)为何RabbitMQ集群仅采用元数据同步的方式？
a.存储空间，如果每个集群节点都拥有所有Queue的完全数据拷贝，那么每个节点的存储空间会非常大，集群的消息积压能力会非常弱（无法通过集群节点的扩容提高消息积压能力）；
b.性能，消息的发布者需要将消息复制到每一个集群节点，对于持久化消息，网络和磁盘同步复制的开销都会明显增加。
(4)节点类型：
①RAM node:内存节点将所有的队列、交换机、绑定、用户、权限和vhost的元数据定义存储在内存中，好处是可以使得像交换机和队列声明等操作更加的快速。
②Disk node:将元数据存储在磁盘中，单节点系统只允许磁盘类型的节点，防止重启RabbitMQ的时候，丢失系统的配置信息。
③RabbitMQ要求在集群中至少有一个磁盘节点，所有其他节点可以是内存节点，当节点加入或者离开集群时，必须要将该变更通知到至少一个磁盘节点，如果集群中唯一的一个磁盘节点崩溃的话，集群仍然可以保持运行，但是无法进行其他操作(包括创建队列、交换器、绑定，添加用户、更改权限、添加和删除集群结点)，直到节点恢复。解决方案：设置两个磁盘节点，至少有一个是可用的，可以保存元数据的更改。
(5)Erlang Cookie是保证不同节点可以相互通信的密钥，要保证集群中的不同节点相互通信必须共享相同的Erlang Cookie。具体的目录存放在/var/lib/rabbitmq/.erlang.cookie。
(6)常见故障
①按正确顺序重启集群，rabbitmqctl cluster_status检查集群健康状态，不正常节点重新加入集群；
②分析是否节点挂掉，手动启动节点，队列阻塞、数据堆积
③保证网络连通正常，服务器TCP连接限制合理；保证消费者正常消费，消费速度大于生产速度；保证脑裂、保证磁盘空间、cpu、内存足够
5、RocketMQ：
6、Kafka：
(1)特性：
①高吞吐，低延迟：Kakfa 最大的特点就是收发消息非常快，kafka 每秒可以处理几十万条消息，它的最低延迟只有几毫秒；
②高伸缩：每个主题(topic) 包含多个分区(partition)，且主题中的分区可以分布在不同的主机(broker)中；
③持久、可靠：Kafka 能够允许数据的持久化存储，消息被持久化到磁盘，并支持数据备份防止数据丢失，Kafka 底层的数据存储是基于 Zookeeper 存储的，Zookeeper 我们知道它的数据能够持久存储；
④容错：允许集群中的节点失败，某个节点宕机，Kafka 集群能够正常工作；
⑤高并发：支持数千个客户端同时读写。
(2)使用场景：
①限流削峰，Kafka 多用于互联网领域某一时刻请求特别多的情况下，可以把请求写入Kafka 中，避免直接请求后端程序导致服务崩溃
②活动跟踪：Kafka 可以用来跟踪用户行为，比如我们经常回去淘宝购物，你打开淘宝的那一刻，你的登陆信息，登陆次数都会作为消息传输到 Kafka ，当你浏览购物的时候，你的浏览信息，你的搜索指数，你的购物爱好都会作为一个个消息传递给 Kafka ，这样就可以生成报告，可以做智能推荐，购买喜好等；
③传递消息：Kafka 另外一个基本用途是传递消息，应用程序向用户发送通知就是通过传递消息来实现的，这些应用组件可以生成消息，而不需要关心消息的格式，也不需要关心消息是如何发送的；
④度量指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告；
⑤日志记录：Kafka 的基本概念来源于提交日志，比如我们可以把数据库的更新发送到 Kafka 上，用来记录数据库的更新时间，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、Hbase、Solr等；
⑥流式处理：流式处理是有一个能够提供多种应用程序的领域；
(3)Kafka 的消息队列的两种模式：
①点对点模式：Kafka 是支持消费者群组的，也就是说 Kafka 中会有一个或者多个消费者，如果一个生产者生产的消息由一个消费者进行消费的话，那么这种模式就是点对点模式
②②发布订阅模式：如果一个生产者或者多个生产者产生的消息能够被多个消费者同时消费的情况，这样的消息队列成为发布订阅模式的消息队列；
(4)Kafka系统架构：如图所示，一个典型的 Kafka 集群中包含若干Producer（可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干Consumer Group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。

(5)Kafka 有四个核心API，它们分别是：
①Producer API，它允许应用程序向一个或多个 topics 上发送消息记录；
②Consumer API，允许应用程序订阅一个或多个 topics 并处理为其生成的记录流；
③Streams API，它允许应用程序作为流处理器，从一个或多个主题中消费输入流并为其生成输出流，有效的将输入流转换为输出流；
④Connector API，它允许构建和运行将 Kafka 主题连接到现有应用程序或数据系统的可用生产者和消费者。例如，关系数据库的连接器可能会捕获对表的所有更改。

(6)Kafka 为何如此之快：Kafka 实现了零拷贝原理来快速移动数据，避免了内核之间的切换。Kafka 可以将数据记录分批发送，从生产者到文件系统（Kafka 主题日志）到消费者，可以端到端的查看这些批次的数据。批处理能够进行更有效的数据压缩并减少 I/O 延迟，Kafka 采取顺序写入磁盘的方式，避免了随机磁盘寻址的浪费，总结一下其实就是四个要点：顺序读写；零拷贝；消息压缩；分批发送。
7、如何保证高可用（从MQ集群架构方面作答）：
(1)RocketMQ集群的多master模式、多master多slave异步复制模式、多master多slave同步双写模式
(2)NameServer集群，在Kafka中是用zookeeper代替，都是用来保存和发现master和slave用的；
(3)Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance
(4)Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高
8、如何保证消息的顺序性：
(1)将消息放入一个消息队列中，只用一个消费者去消费该队列；
(2)保证入队有序
9、如何保证消息不被重复消费，幂等性：
(1)拿消息做数据库的insert操作，唯一主键确保不产生脏数据;
(2)拿消息做redis的set操作，set操作本来就是幂等操作；
(3)大招，使用第三方介质，做消费记录，给消息分配一个全局id，消费者开始消费前，做消费记录查询；


网络通信协议和Web：
1、Web（WorldWideWeb）全球广域网，是一种基于超文本HTML和HTTP的、全球性的、动态交互的、跨平台的分布式图形信息系统。建立在Internet上的一种网络服务
2、http三个版本区别：
(1)1.0短链接（100张图，100次tcp握手和挥手）
(2)1.1长连接（100张图，1次tcp握手挥手）
(3)2.0长连接+多路复用模型（五大模型之一）
3、DNS：域名服务器（DomainNameServer）提供域名解析的服务，实现域名到ip地址之间的转化，网络之间是通过ip连接的，域名只是为了方便记忆；
4、路由：连接多个网络或网段的网络设备，它能将不同网络或网段之间的数据信息进行“翻译”，以使它们能够相互“读”懂对方的数据，从而构成一个更大的网络。
5、Web响应状态码：是服务端对客户端请求的一种状态响应，不同的状态码代表着服务端对请求的不同响应结果。
6、网络常见缩写##
(1)LAN：局部区域网，局域网，本地网（全写为localareanetwork）;
(2)DHCP：（动态主机配置协议）是一个局域网的网络协议。
(3)VPN：（虚拟专用网络）通过一个公用互联网络建立的一个临时、安全、稳定隧道，使用这条隧道可以对数据进行几倍加密，主要使用在企业办公当中。
(4)ICMP：（因特网控制报文协议）TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。这些控制消息不传输用户数据，但是对于用户数据的传递起着重要的作用。ICMP报文有两种：差错报告报文和询问报文；
(5)RPC：（远程过程调用协议）是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。RPC协议假定某些传输协议的存在，如TCP或UDP，为通信程序之间携带信息数据。在OSI网络通信模型中，RPC跨越了传输层和应用层。RPC使得开发包括网络分布式、多程序在内的应用程序更加容易。
(6)ARP（Address Resolution Protocol)（地址解析协议）提供了网络层地址（IP地址）到物理地址（mac地址）之间的动态映射。网络层以上的协议用IP地址来标识网络接口，但以太数据帧传输时，以物理地址来标识网络接口，因此我们需要进行IP地址与物理地址之间的转化。
(7)API：（应用编程接口）是一些预先定义的函数，或指软件系统不同组成部分，衔接的约定。目的是提供应用程序与开发人员基于某软件或硬件得以访问一组例程的能力，而又无需访问原码，或理解内部工作机制的细节。
(8)ORM：（对象关系映射）用于实现面向对象编程语言里不同类型系统的数据之间的转换的一种程序技术。ORM提供了对数据库的映射，不用sql直接编码，能够像操作对象一样从数据库获取数据。提高了开发效率。ORM可以自动对实体对象与数据库中的表进行字段与属性的映射，所以我们实际可能已经不需要一个专用的、庞大的数据访问层。
7、对websocket协议的认识。
(1)是HTML5开始提供的一种 浏览器与服务器 间 进行 全双工通讯的网络技术。
(2)Socket是TCP层的封装，浏览器和服务器只需要做一个握手的动作就可以实现数据的相互传送；
(3)Header很小，信息传输效率高；服务器可以主动推送数据到浏览器；
(4)socket长连接：指的是客户端和服务端之间保持一个socket连接长时间不断开，保持连接的情况下可以节省系统资源；
8、网络延时、完整性约束 
(1)时延：是指一个报文或分组从一个网络（或一条链路）的一端传送到另一端所需的时间；
(2)数据完整性约束：为了防止不符合规范的数据进入数据库，在用户对数据进行插入、修改、删除等操作时，DBMS自动按照一定的约束条件对数据进行监测，使不符合规范的数据不能进入数据库，以确保数据库中存储的数据正确、有效、相容；
9、脏数据：
(1)是指源系统中的数据 不在给定的范围内或对于实际业务毫无意义，或是数据格式非法，以及在源系统中存在不规范的编码和含糊的业务逻辑。
(2)在数据库技术中,脏数据产生于临时更新（脏读）。例如：事务A更新了某个数据项X，由于某种原因事务A回滚。但是在回滚之前，另一个事务B读取了数据项X的值，A回滚了事务，数据项恢复了原值。事务B读取的就是数据项X的就是一个“临时”的值，就是脏数据。
10、《图解TCP/IP》读书笔记：https://www.cnblogs.com/edisonchou/p/5987827.html
11、数据在TCP层称为流（Stream），数据分组称为分段（Segment）。作为比较，数据在IP层称为Datagram，数据分组称为分片（Fragment）。 UDP 中分组称为Message。
12、粘包现象值存在于TCP协议，UDP协议不存在粘包的情况
(1)粘包原因：
①发送端：连续发送多个小的数据包（就是指字节数小于报文段-MSS的大小），由于Nagle优化算法导致的几个小包合并为一个包。
②接收端：一次从自己的缓冲区中能够读取的字节数少于对端发送的一个数据包的字节数，导致本段在读取的时候数据不能一次读取完毕
(2)拆包解决：提前告知数据大小，将数据长度合并到报文中，由程序标识数据流的结束。
13、广域网（WAN,公网,外网），就是我们通常所说的Internet，它是一个遍及全世界的网络。 局域网（LAN,私网,内网），相对于广域网（WAN）而言，主要是指在小范围内的计算机互联网络。这个“小范围”可以是一个家庭，一所学校，一家公司，或者是一个政府部门。 BT中常常提到的公网、 外网，即广域网（WAN）；BT中常常提到私网、内网，即局域网（LAN）。 广域网上的每一台电脑（或其他网络设备）都有一个或多个广域网IP地址（或者说公网、外网IP地址），广域网IP地址一般要到ISP处交费之后才能申请到， 广域网IP地址不能重复；局域网（LAN）上的每一台电脑（或其他网络设备）都有一个或多个局域网IP地址（或者说私网、内网IP地址）， 局域网IP地址是局域网内部分配的，不同局域网的IP地址可以重复，不会相互影响。
14、路由器和交换机？
(1)交换机工作在OSI的第二层（数据链路层），所以它的工作原理比较简单，而路由器工作在OSI的第三层（网络层），可以得到更多的协议信息， 路由器可以做出更加智能的转发决策。 　
(2)交换机是利用物理地址或者说MAC地址来确定转发数据的目的地址。而路由器则是利用不同网络的ID号（即IP地址）来确定数据转发的地址。 IP地址是在软件中实现的，描述的是设备所在的网络，有时这些第三层的地址也称为协议地址或者网络地址。MAC地址通常是硬件自带的，由网卡生产商来分配的， 而且已经固化到了网卡中去，一般来说是不可更改的。而IP地址则通常由网络管理员或系统自动分配。 
(3)传统的交换机只能分割冲突域，不能分割广播域；而路由器可以分割广播域由交换机连接的网段仍属于同一个广播域，广播数据包会在交换机连接的所有网段上传播， 在某些情况下会导致通信拥挤和安全漏洞。连接到路由器上的网段会被分配成不同的广播域，广播数据不会穿过路由器。虽然第三层以上交换机具有VLAN功能， 也可以分割广播域，但是各子广播域之间是不能通信交流的，它们之间的交流仍然需要路由器。 　　
(4)路由器提供了防火墙的服务。路由器仅仅转发特定地址的数据包，不传送不支持路由协议的数据包传送和未知目标网络数据包的传送，从而可以防止广播风暴。
15、CDN的全称是Content Delivery Network，即内容分发网络。其基本思路是尽可能避开互联网上有可能影响数据传输速度和稳定性的瓶颈和环节，使内容传输的更快、更稳定。 通过在网络各处放置节点服务器所构成的在现有的互联网基础之上的一层智能虚拟网络，CDN系统能够实时地根据网络流量和各节点的连接、 负载状况以及到用户的距离和响应时间等综合信息将用户的请求重新导向离用户最近的服务节点上。其目的是使用户可就近取得所需内容，解决 Internet网络拥挤的状况，提高用户访问网站的响应速度。
16、Haproxy是一个使用C语言编写的自由及开放源代码软件，其提供高可用性、负载均衡，以及基于TCP和HTTP的应用程序代理。 HAProxy特别适用于那些负载特大的web站点，这些站点通常又需要会话保持或七层处理。HAProxy运行在当前的硬件上 ，完全可以支持数以万计的并发连接。并且它的运行模式使得它可以很简单安全的整合进您当前的架构中， 同时可以保护你的web服务器不被暴露到网络上。 HAProxy实现了一种事件驱动, 单一进程模型，此模型支持非常大的并发连接数。多进程或多线程模型受内存限制 、系统调度器限制以及无处不在的锁限制， 很少能处理数千并发连接。事件驱动模型因为在有更好的资源和时间管理的用户空间( User - Space) 实现所有这些任务，所以没有这些问题。此模型的弊端是，在多核系统上，这些程序通常扩展性较差。这就是为什么他们必须进行优化以 使每个CPU时间片(Cycle) 做更多的工作。
17、keepalived是一个类似于Layer2,4,7交换机制的软件。是Linux集群管理中保证集群高可用的一个服务软件，其功能是用来防止单点故障。keepalived的工作原理：keepalived是基于VRRP协议实现的保证集群高可用的一个服务软件，主要功能是实现真机的故障隔离和负载均衡器间的失败切换，防止单点故障。在了解keepalived原理之前先了解一下VRRP协议。
18、VRRP协议：Virtual Route Redundancy Protocol虚拟路由冗余协议。是一种容错协议，保证当主机的下一跳路由出现故障时，由另一台路由器来代替出现故障的路由器进行工作，从而保持网络通信的连续性和可靠性。
19、单点登录：SSO（Single Sign On），是指在一个多系统共存的环境下，用户在一处登录后，就不用在其它系统中登录，也就是用户的一次登录就能得到其它所有系统的信任；对于大型系统来说使用单点登录可以减少用户很多的麻烦，多台主机负载均衡的话就涉及到session共享的问题，实现单点登录要解决如何产生和存储信任，再就是其它系统如何验证这个信任的有效性，因此要点有两个：存储信任，-验证信任：①以Cookie作为凭借媒介，②通过JSONP实现，③通过页面重定向的方式，④使用独立登录系统；
20、网络掩码的作用：将某个IP地址划分成网络地址和主机地址两部分




kubernates：
1、k8s全称kubernetes，是源于谷歌内部的大规模集群管理系统Borg，面向应用的容器集群部署和管理的系统；一个K8S系统，通常称为一个K8S集群（Cluster）。这个集群主要包括两个部分：一个Master节点（主节点）和一群Node节点（计算节点）、
2、kubectl：用于运行Kubernetes集群命令的管理工具；
3、kubernetes主要功能：
(1)数据卷：Pod中容器之间共享数据，可以使用数据卷；
(2)应用程序健康检查：容器内服务可能进程阻塞无法处理请求，可以设置监控检查策略保证应用健壮性；
(3)复制应用实例：控制器维护着pod副本数量，保证一个pod或一组同类pod数量始终可用；
(4)弹性伸缩：根据设定的指标（CPU利用率）自动缩放Pod副本数；
(5)服务发现：使用环境变量或者DNS服务插件保证容器中程序发现pod入口访问地址；
(6)负载均衡：一个pod副本分配一个私有的集群IP地址，负载均衡转发请求到后端容器。在集群内部其它pod可通过这个ClusterIP访问应用；
(7)滚动更新：更新服务不中断，一次更新一个pod，而不是删除整个服务；
(8)资源监控：Node节点组件集成cAdvisor资源收集工具，可通过Heapster汇总整个集群节点资源数据，然后存储到InfluxDB时序数据库，再由Grafana展示；
(9)提供认证和授权：支持角色访问控制（RBAC）认证授权等策略；
4、基本对象概念：
(1)pod：kubernetes对象模型中可部署的最小对象；
①最小部署单元，一个pod有一个或多个容器组成，Pod中容器共享存储和网络，在同一台Docker主机上运行；一个Pod代表集群上正在运行的一个进程；
②Pod中的容器在集群中Node上被自动分配，容器之间可以共享资源、网络和相互依赖关系，并同时被调度使用。Pods提供两种共享资源：网络和存储：
1)网络：每个Pod被分配一个独立的IP地址，Pod中的每个容器共享网络命名空间，包括IP地址和网络端口。Pod内的容器可以使用localhost相互通信。当Pod中的容器与Pod外部通信时，他们必须协调如何使用共享网络资源（如端口）。
2)存储：Pod可以指定一组共享存储volumes。Pod中的所有容器都可以访问共享volumes，允许这些容器共享数据。volumes还用于Pod中的数据持久化，以防其中一个容器需要重新启动而丢失数据。有关Kubernetes如何在Pod中实现共享存储的更多信息，请参考Volumes；
(2)Service：一个应用服务器，定义了Pod逻辑集合和访间这个Pod集合的策略。Service通过LableSelector选择一组Pod提供服务。Service代理Pod集合对外表现是为一个访问入口，分配一个集群IP地址，来自这个IP的请求将负载均衡转发后端Pod中的容器。
(3)Volume：数据卷，共享Pod中容器使用的数据；
(4)Namespace：命名空间也称为虚拟集群，命名空间将对象逻辑上分配到不同Namespace，可以是不同的项目、用户等区分管理，并设定控制策略，从而实现多租户。
(5)Lable：标签用于区分对象(比如Pod、Service)，键/值对存在；每个对象可以有多个标签，通过标签关联对象。
5、基于基本对象更高层次抽象：
(1)ReplicaSet：下一代ReplicationController。确保任何给定时间指定的Pod副本数量，并提供声明式更新等功能。RC与RS唯一区别就是lableselector支持不同，RS支持新的基于集合的标签，RC仅支持基于等式的标签。
(2)Deployment：Deployment是一个更高层次的API对象，它管理ReplicaSets和Pod,并提供声明式更新等功能。官方建议使用Deployment管理ReplicaSets,而不是直接使用ReplicaSets,这就意味着可能永远不需要直接操作ReplicaSet对象。
(3)StatefulSet：适合持久性的应用程序，有唯一的网络标识符(IP)。持久存储，有序的部署、扩展、删除和滚动更新。
(4)DaemonSet：确保所有(或一些)节点运行同一个Pod。当节点加入Kubernetes集群中，Pod会被调度到该节点上运行，当节点从集群中，移除时，DaemonSet的Pod会被删除。删除DaemonSet会清理它所有创建的Pod。
(5)Job：一次性任务，运行完成后Pod销毁，不再重新启动新容器。还可以任务定时运行。
6、系统架构及组件功能：
(1)Master组件：
①kubeapiserver：KubernetesAPI，集群的统一入口，各组件协调者，以HTTPAPI提供接口服务，所有对象资源的增删改查和监听操作都交给APIServer处理后再提交给Etcd存储。
②kube-controller-manager：处理集群中常规后台任务，一个资源对应一个控制器，而ControllerManager就是负责管理这些控制器的;
1)Controller：可以创建和管理多个Pod，提供副本管理、滚动升级和集群级别的自愈能力。例如，如果一个Node故障，Controller就能自动将该节点上的Pod调度到其他健康的Node上。
③kube-scheduler：根据调度算法为新创建的Pod选择一个Node节点。,
(2)Node组件:
①kubelet：是Master在Node节点上的Agent，管理本机运行容器的生命周期，比如创建容器、Pod挂载数据卷、下载secret、获取容器和节点状态等工作。kubelet将每个Pod转换成一组容器。
②kubeproxy：在Node节点上实现Pod网络代理，维护网络规则和四层负载均衡工作。
③docker或rocket/rkt：运行容器。,
(3)第三方服务:
①etcd：分布式键值存储系统，用于保持集群状态，比如Pod，Service等对象信息。


算法：
1、算法思想：
(1)动态规划：把复杂的问题分阶段进行简化，逐步简化成简单的问题。动态规划中包含三个重要的概念，最优子结构、边界、状态转移公式。
(2)贪心算法：
2、排序算法：
3、查找算法：
排序算法：
1、分治算法：
2、深度优先、广度优先：
(1)https://blog.csdn.net/qq_33204444/article/details/79202347
(2)https://blog.csdn.net/qq_33204444/article/details/79192626
3、一致性hash和hash槽：
(1)一致性hash，：
①在解决分布式系统中负载均衡的问题时候可以使用Hash算法让固定的一部分请求落到同一台服务器上，这样每台服务器固定处理一部分请求（并维护这些请求的信息），起到负载均衡的作用。但是普通的余数hash（hash(比如用户id)%服务器机器数）算法伸缩性很差，当新增或者下线服务器机器时候，用户id与服务器的映射关系会大量失效。
②一致性hash则利用hash环（一个0-2^32的闭合圆）对其进行了改进，防止雪崩的发生。
③虚拟节点：当服务器节点比较少的时候会出现上节所说的一致性hash倾斜的问题，一个解决方法是多加机器，但是加机器是有成本的，那么就加虚拟节点。
④首先把服务器的多个ip映射到了一致性hash环上，然后根据hash值在hash环上的位置顺时针找距离最近的ip作为路由ip。当一个ip处理的一部分用户的映射关系被破坏了，则负责处理的请求被顺时针下一个节点委托处理，避免了余数hash中一个服务器下线，用户id与服务器的映射关系会大量失效的情况。
(2)hash槽：
①一致性hash如果删除节点或者一个节点失效，其负载会全落在下一个节点，如果下一个节点撑不起这种负载，则可能会形成节点的循环雪崩；节点太少的话又容易产生数据倾斜，添加节点会导致一部分负载的重新节点迁移；
②rediscluster采用数据分片的哈希槽来进行数据存储和数据的读取。rediscluster一共有2^14（16384）个槽，所有的master节点都会有一个槽区比如0～1000，槽数是可以迁移的。master节点的slave节点不分配槽，只拥有读权限。但是注意在代码中rediscluster执行读写操作的都是master节点，并不是你想的读是从节点，写是主节点。第一次新建rediscluster时，16384个槽是被master节点均匀分布的。
(3)一致性哈希是创建虚拟节点来实现节点宕机后的数据转移并保证数据的安全性和集群的可用性的。rediscluster是采用master节点有多个slave节点机制来保证数据的完整性的,master节点写入数据，slave节点同步数据。当master节点挂机后，slave节点会通过选举机制选举出一个节点变成master节点，实现高可用。但是这里有一点需要考虑，如果master节点存在热点缓存，某一个时刻某个key的访问急剧增高，这时该mater节点可能操劳过度而死，随后从节点选举为主节点后，同样宕机，一次类推，造成缓存雪崩。
(4)和一致性哈希相比，哈希槽不是闭合的，key的定位规则是根据CRC-16(key)%16384的值来判断属于哪个槽区，从而判断该key属于哪个节点，而一致性哈希是根据hash(key)的值来顺时针找第一个hash(ip)的节点，从而确定key存储在哪个节点。
4、复杂度分析：


数据结构：
1、三种常见的数据结构：
(1)线性数据结构：数组、线性表、栈、队列；
①数组：在内存中是连续存储，可以利用下标索引进行随机访问，数组的查找速度快，但插入和删除效率低、可能浪费内存（数组申请的内存不一定用完）；
②链表：链式存储结构，每个元素增设指针域，用来指向后继元素，插入删除速度快、内存利用率高，不会浪费内存、大小没有固定，拓展很灵活，但在访问元素的时候只能通过线性的方式由前到后顺序访问，所以访问效率比数组要低，不能随机查找，必须从第一个开始遍历，查找效率低；
1)链表从堆中分配空间,自由度大但是申请管理比较麻烦
③栈、队列和线性表：可采用顺序存储和链式存储的方法进行存储：
1)队列：只允许在序列两端进行操作，一般队列也被称为先进先出的线性结构；
2)栈：只允许在序列末端进行操作，栈的操作只能在栈顶进行，一般栈又被称为后进先出或先进后出的线性结构；
3)线性表：许在序列任意位置进行操作，线性表的操作位置不受限制，线性表的操作十分灵活，常用操作包括在任意位置插入和删除，以及查询和修改任意位置的元素（单链表、双向链表、循环链表和双向循环链表）；
(2)树形数据结构：
①-结点间具有层次关系，每一层的一个结点能且只能和上一层的一个结点相关，但同时可以和下一层的多个结点相关，称为“一对多”关系，常见类型有：树、堆：
1)二叉树：是一种递归数据结构；
2)完全二叉树：
3)二叉查找树：
4)平衡二叉树：
5)树：
6)堆：
7)并查集：
8)B树/B+树
(3)图形数据结构：
①在图形结构中，允许多个结点之间相关，称为“多对多”关系，可分为有向图和无向图；
2、网络通信数据格式：
(1)JSON：
(2)XML：
(3)ProtoBuf：
3、


负载均衡：
1、负载共享，是指对系统中的负载情况进行动态调整，以尽量消除或减少系统中各节点负载不均衡的现象。
2、具体实现方法是将过载节点上的任务转移到其他轻载节点上，尽可能实现系统各节点的负载平衡，从而提高系统的吞吐量。
3、负载共享有利于统筹管理分布式系统中的各种资源，便于利用共享信息及其服务机制扩大系统的处理能力。
4、动态负载共享策略是指把系统中各节点上已有的负载作为参考信息，在运行过程中，根据系统中各节点的负载状况，随时调整负载的分配，使各节点尽可能保持负载的平衡。


后端框架：
1、Web应用程序是一个各种编程语言一个非常流行的应用领域；它的后台开发涉及到的知识有：
(1)模型设计：关系型数据库模型设计
(2)SQL、ORM
(3)Restful API设计
2、MVC框架：
(1)MVC是模型(model)－视图(view)－控制器(controller)的缩写，是一种软件设计典范，它用一种业务逻辑、数据、界面显示分离的方法组织代码，将业务逻辑聚集到一个部件里面，在改进和个性化定制界面及用户交互的同时，不需要重新编写业务逻辑。
①Model（模型）是应用程序中用于处理应用程序数据逻辑的部分，通常模型对象负责在数据库中存取数据。
②View（视图）是应用程序中处理数据显示的部分，通常视图是依据模型数据创建的。
③Controller（控制器）是应用程序中处理用户交互的部分，通常控制器负责从视图读取数据，控制用户输入，并向模型发送数据。
(2)MVC分层有助于管理复杂的应用程序，并简化了分组开发；
3、框架和设计模式：
(1)框架：（MVC、ORM…）：通常是代码重用，来对软件设计进行分工，是大智慧；
(2)设计模式：比框架更抽象，是对具体问题提出解决方案，以提高代码复用率，降低耦合度，是小技巧；


API网关：
1、网关实质上是一个网络通向其他网络的IP地址，只有设置好网关的IP地址，TCP/IP协议才能实现不同网络之间的相互通信。
(1)网关的IP地址是 具有路由功能的设备 的IP地址；
(2)具有路由功能的设备有：路由器、启用了路由协议的服务器（实质上相当于一台路由器）、代理服务器（也相当于一台路由器）。
2、API网关就像一个反向代理，它将获取客户端请求并重定向，很好的解决了微服务调用、统一接入等问题；
(1)通过暴漏一个公开的IP，保护内部的所有的私有的IP地址（后端的微服务），从而增强系统的安全性；
(2)减低请求延迟，聚合模式，专有的内部IP；
(3)应用程序和仅一个API网关，而不是与多个API耦合；
3、在微服务中网关具备的功能：
(1)身份验证和鉴权；
(2)服务发现；
(3)重试策略/断路器；
(4)限流
(5)负载均衡
(6)日志/追踪
(7)查询信息
(8)IP白/黑名单
4、提高可用性：API网关做扩展，做一个单点故障处理，部署第二第三个实例；
5、Nginx是一款自由的、开源的、高性能的HTTP服务器和反向代理服务器；同时也是一个IMAP、POP3、SMTP代理服务器；Nginx可以作为一个HTTP服务器进行网站的发布处理，另外Nginx可以作为反向代理进行负载均衡的实现。
(1)服务器在设计之初受到当时环境的局限，例如当时的用户规模，网络带宽，产品特点等局限并且各自的定位和发展都不尽相同。这也使得各个WEB服务器有着各自鲜明的特点。
①Apache的发展时期很长，而且是毫无争议的世界第一大服务器。它有着很多优点：稳定、开源、跨平台等等。它出现的时间太长了，它兴起的年代，互联网产业远远比不上现在。所以它被设计为一个重量级的。它不支持高并发的服务器。在Apache上运行数以万计的并发访问，会导致服务器消耗大量内存。操作系统对其进行进程或线程间的切换也消耗了大量的CPU资源，导致HTTP请求的平均响应速度降低。这些都决定了Apache不可能成为高性能WEB服务器，轻量级高并发服务器Nginx就应运而生了。
②Nginx使用基于事件驱动架构，使得其可以支持数以百万级别的TCP连接。高度的模块化和自由软件许可证使得第三方模块层出不穷（这是个开源的时代啊~）。Nginx是一个跨平台服务器，可以运行在Linux，Windows，FreeBSD，Solaris，AIX，Mac OS等操作系统上。
(2)Nginx的作用：
①静态HTTP服务器。
②反向代理服务器。客户端本来可以直接通过HTTP协议访问某网站应用服务器，网站管理员可以在中间加上一个Nginx，客户端请求Nginx，Nginx请求应用服务器， 然后将结果返回给客户端，此时Nginx就是反向代理服务器。（说到代理，首先我们要明确一个概念，所谓代理就是一个代表、一个渠道；此时就涉及到两个角色，一个是被代理角色，一个是目标角色，被代理角色通过这个代理访问目标角色完成一些任务的过程称为代理操作过程；如同生活中的专卖店~客人到adidas专卖店买了一双鞋，这个专卖店就是代理，被代理角色就是adidas厂家，目标角色就是用户。）
③负载均衡。当网站访问量非常大，网站站长开心赚钱的同时，也摊上事儿了。因为网站越来越慢，一台服务器已经不够用了。于是将同一个应用部署在多台服务器上， 将大量用户的请求分配给多台机器处理。同时带来的好处是，其中一台服务器万一挂了，只要还有其他服务器正常运行，就不会影响用户使用。
④虚拟主机。有的网站访问量大，需要负载均衡。然而并不是所有网站都如此出色，有的网站，由于访问量太小，需要节省成本，将多个网站部署在同一台服务器上。 例如将www.aaa.com和www.bbb.com两个网站部署在同一台服务器上，两个域名解析到同一个IP地址，但是用户通过两个域名却可以打开两个完全不同的网站， 互相不影响，就像访问两个服务器一样，所以叫两个虚拟主机。
⑤FastCGI。Nginx本身不支持PHP等语言，但是它可以通过FastCGI来将请求扔给某些语言或框架处理（例如PHP、Python、Perl）。
6、Kong：
(1)是适用于多云和混合云的下一代API平台；
①开源并支持私有部署的一款API网关框架；
②基于lua语言、nginx以及OpenResty研发；
③高性能以及其强大的扩展性（插件）；





RESTful API：
1、Restful发展背景： 
(1)SOAP（简单对象访问协议），是一种轻量、简单、基于XML的一种的交换数据协议规范，用在WEB上交换结构化的和固化的信息。
(2)SOAP的Web Service解决方案虽然较为成熟，且安全性较好，但是使用门槛较高，在大并发情况下会有性能问题，在互联网上使用不太普及，因此并不太适合Web 2.0网站服务使用，目前大量的Web 2.0网站使用另外一种解决方案——REST。
(3)REST架构是针对Web应用而设计的，其目的是为了降低开发的复杂性，提高系统的可伸缩性。
(4)RESTful 是典型的基于HTTP的协议；
2、REST的架构设计：（Representational State Transfer）
(1)是一种轻量级的Web Service架构风格，其实现和操作明显比SOAP和XML-RPC更为简洁，可以完全通过HTTP协议实现，还可以利用缓存Cache来提高响应速度，在性能、效率和易用性上都优于SOAP协议。
(2)REST架构遵循了CRUD原则，对于资源只需要四种行为：Create（创建）、Read（读取）、Update（更新）和Delete（删除）就可以完成对其操作和处理。这四个操作是一种原子操作，通过它们可以构造更复杂的操作过程，如数学上四则运算是数字的最基本的运算一样。
(3)REST架构中获取、创建、修改和删除资源的操作正好对应HTTP协议提供的GET、POST、PUT和DELETE方法，因此REST把HTTP对一个URL资源的操作限制在这四个操作之内。这种针对网络应用的设计和开发方式，可以降低开发的复杂性，提高系统的可伸缩性。
3、REST的设计准则：
(1)网络上的所有实体（文本、图片、音频、视频）都被抽象为资源（resource），资源总是以一定的格式来表现自己。文本用txt、html；图片用JPG、JPEG等等。而JSON是RESTful API中最常用的资源表现格式。
(2)每个资源对应一个唯一的资源标识符（resource identifier），对资源的各种操作不会改变资源标识符；
(3)通过通用的连接接口（generic connector interface）对资源进行操作（统一接口），对于业务数据的CRUD，RESTful 用HTTP方法与之对应。
(4)所有的操作都是无状态的（stateless）。这里引入一个幂等性的概念，无论一个操作被执行一次还是多次，执行后的效果都相同。比如对某资源发送GET请求，如果访问一次和访问十次获得的数据一样，那么就说这个请求具有幂等性。
(5)URL中只能有名词，不能出现动词，（5）因为在REST要求对资源的操作由HTTP 方法给出，而方法是由HTTP 请求报文头部给出的，自然不需要在URL中暴露操作方式。
4、REST名词解释：representation state transfer（表现层状态转化）
(1)Resource: 资源，即数据，存在互联网上的可被访问的实体
(2)Representation：数据的某种表现形式，如HTML, JSON。
(3)State Transfer：状态变化，HTTP方法实现
5、备注：
(1)REST不仅仅是一种崭新的架构，它更是一种全新的Web开发过程中的思维方式（通过URL来设计系统结构）；
(2)REST是一套简单的设计原则、一种架构风格（或模式），不是一种具体的标准或架构；
(3)著名的Delicious和Flickr都提供基于REST风格的API使用，客户端调用也极其方便；

常用设计模式：
1、工作中用到的一些架构方面的其它设计模式：
(1)单库单应用模式：最简单的，可能大家都见过
(2)内容分发模式：目前用的比较多
(3)查询分离模式：对于大并发的查询、业务
(4)微服务模式：适用于复杂的业务模式的拆解
(5)多级缓存模式：可以把缓存玩的很好
(6)分库分表模式：解决单机数据库瓶颈
(7)弹性伸缩模式：解决波峰波谷业务流量不均匀的方法之一
(8)多机房模式：解决高可用、高性能的一种方法
2、池子的设计：内存池、进程池、线程池
(1)池的概念：服务器的硬件资源“充裕”，那提高服务器性能的一个很直接的方法就是以空间换时间，即“浪费”服务器的硬件资源，以换取其运行效率。
①池是一组资源的集合，这组资源在服务器启动之初就完全被创建并初始化，这称为静态资源分配。当服务器进入正式运行阶段，即开始处理客户请求的时候，如果它需要相关的资源，就可以直接从池中获取，无需动态分配。
②直接从池中取得所需资源比动态分配资源的速度要快得多，因为分配系统资源的系统调用都是很耗时的。当服务器处理完一个客户连接后，可以把相关的资源放回池中，无需执行系统调用来释放资源。从最终效果来看，池相当于服务器管理系统资源的应用设施，它避免了服务器对内核的频繁访问。
(2)内存池：
①内存池是一种内存分配方式。直接使用new、malloc等系统调用申请分配内存，由于所申请内存块的大小不定，当频繁使用时会造成大量的内存碎片并进而降低性能。
②内存池则是在真正使用内存之前，先申请分配一定数量的、大小相等(一般情况下)的内存块留作备用。当有新的内存需求时，就从内存池中分出一部分内存块，若内存块不够再继续申请新的内存，使得内存分配效率得到提升。
③从内存池可分配内存单元大小来分，可以分为固定内存池和可变内存池。所谓固定内存池是指应用程序每次从内存池中分配出来的内存单元大小事先已经确定，是固定不变的；而可变内存池则每次分配的内存单元大小可以按需变化，应用范围更广，而性能比固定内存池要低。
(3)进程池和线程池
①从线程安全的角度来分，内存池可以分为单线程内存池和多线程内存池。进程池和线程池相似，对进程池的描述也适用于线程池
②进程池是由服务器预先创建的一组子进程，这些子进程的数目在 3~10 个之间（当然这只是典型情况）。线程池中的线程数量应该和 CPU 数量差不多。进程池中的所有子进程都运行着相同的代码，并具有相同的属性，比如优先级、 PGID 等。当有新的任务来到时，主进程将通过某种方式选择进程池中的某一个子进程来为之服务。相比于动态创建子进程，选择一个已经存在的子进程的代价显得小得多。至于主进程选择哪个子进程来为新任务服务，则有两种方法：
1)主进程使用某种算法来主动选择子进程。最简单、最常用的算法是随机算法和 Round Robin （轮流算法）。
2)主进程和所有子进程通过一个共享的工作队列来同步，子进程都睡眠在该工作队列上。当有新的任务到来时，主进程将任务添加到工作队列中。这将唤醒正在等待任务的子进程，不过只有一个子进程将获得新任务的“接管权”，它可以从工作队列中取出任务并执行之，而其他子进程将继续睡眠在工作队列上。
③当选择好子进程后，主进程还需要使用某种通知机制来告诉目标子进程有新任务需要处理，并传递必要的数据。最简单的方式是，在父进程和子进程之间预先建立好一条管道，然后通过管道来实现所有的进程间通信。在父线程和子线程之间传递数据就要简单得多，因为我们可以把这些数据定义为全局，那么它们本身就是被所有线程共享的。
(4)线程池主要用于：
①需要大量的线程来完成任务，且完成任务的时间比较短（WEB服务器完成网页请求这样的任务，单个任务小，而任务数量巨大），但对于长时间的任务（比如一个Telnet连接请求，因为Telnet会话时间比线程的创建时间大多了）线程池的优点就不明显了。
②对性能要求苛刻的应用，比如要求服务器迅速响应客户请求。
③接受突发性的大量请求，但不至于使服务器因此产生大量线程的应用。
3、生产者消费者模型：
(1)属于面向过程的编程模型，该模式还需要有一个缓冲区处于生产者和消费者之间，作为一个中介。
①生产者把数据放入缓冲区，而消费者从缓冲区取出数据（避免直接依赖，降低耦合，异步防止阻塞），生产者与消费者模式是通过一个容器来解决生产者与消费者的强耦合关系，
②生产者与消费者之间不直接进行通讯，而是利用阻塞队列来进行通讯， 生产者生成数据后直接丢给阻塞队列，消费者需要数据则从阻塞队列获取，
③实际应用中，生产者与消费者模式则主要解决生产者与消费者生产与消费的速率不一致的问题， 达到平衡生产者与消费者的处理能力，而阻塞队列则相当于缓冲区。
④还有一个比较典型的例子便是日志的记录，多线程产生日志，但写日志由于文件独占，不能多线程来写，于是我们就可以把线程压入队列，由日志线程来读取队列数据，完成写日志的操作。
4、添加中间件：
(1)什么是中间件：是基础软件的一大类，属于可复用软件的范畴。中间件处于操作系统软件与用户的应用软件的中间。中间件在操作系统、网络和数据库之上，应用软件的下层，总的作用是为处于自己上层的应用软件提供运行与开发的环境，帮助用户灵活、高效地开发和集成复杂的应用软件 ；IDC的定义是：中间件是一种独立的系统软件或服务程序，分布式应用软件借助这种软件在不同的技术之间共享资源，中间件位于客户机服务器的操作系统之上，管理计算资源和网络通信。
(2)中间件解决的问题是：在中间件产生以前，应用软件直接使用操作系统、网络协议和数据库等开发，这些都是计算机最底层的东西，越底层越复杂，开发者不得不面临许多很棘手的问题，如操作系统的多样性，繁杂的网络程序设计、管理，复杂多变的网络环境，数据分散处理带来的不一致性问题、性能和效率、安全，等等。这些与用户的业务没有直接关系，但又必须解决，耗费了大量有限的时间和精力。于是，有人提出能不能将应用软件所要面临的共性问题进行提炼、抽象，在操作系统之上再形成一个可复用的部分，供成千上万的应用软件重复使用。这一技术思想最终构成了中间件这类的软件。中间件屏蔽了底层操作系统的复杂性，使程序开发人员面对一个简单而统一的开发环境，减少程序设计的复杂性。


新名词和技术：
1、DPI：一种基于应用层的流量检测和控制技术，称为“深度包检测”，还可以通过设置不懂的权重，来分离各种数据包，从而更高效的应用有限的网络宽带资源，具有管理网络性能的用处。
